

## تشخیص تقلب در بیمه خودرو با استفاده از جنگل های تصادفی  و تکنیک بیش نمونه گیری اقلیت مصنوعی

**چکیده**. در طول چند سال گذشته، رشد قابل‌توجهی در تعداد فعالیت‌های کلاهبردارانه توسط بیمه‌شونده وجود داشته‌است. فریب عمدی ارائه دهندگان بیمه با حذف حقایق و پنهان کردن جزئیات در حالی که ادعا برای بیمه منجر به از دست دادن بخش قابل‌توجه پول و ارزش مشتری شده‌است. برای اینکه این ریسک‌ها را تحت کنترل نگاه دارید؛ چارچوب مناسبی برای نظارت قضایی بر تقلب در بیمه لازم است. در این مقاله، ما یک رویکرد جدید برای ساخت یک آشکارساز کلاهبرداری بیمه خودکار مبتنی بر یادگیری ماشین را نشان می دهیم که ادعاهای جعلی بیمه را از مجموعه داده بیش از ۱۵۴۲۰ رکورد ادعای اتومبیل پیش بینی خواهد کرد. مدل پیشنهادی با استفاده از تکنیک  بیش نمونه گیری اقلیت مصنوعی (‏SMOTE) ‏ساخته شده‌است که عدم توازن کلاس مجموعه داده را از بین می برد. ما از روش طبقه بندی جنگل های تصادفی برای طبقه‌بندی سوابق ادعا استفاده می‌کنیم. داده‌های مورد استفاده در آزمایش ما از مجموعه داده‌های بیمه اتومبیل که به صورت عمومی در دسترس هستند، گرفته شده‌است. نتایج رویکرد ما با دیگر مدل‌های موجود براساس معیارهای عملکرد مختلف مقایسه شدند. ​

**کلمات کلیدی:** تقلب بیمه، عدم توازن کلاس، مطالبات بیمه خودرو، نمونه گیری بیش از حد، طبقه‌بندی، جنگل های تصادفی، معیارهای عملکرد 

### 1. مقدمه  

صنعت بیمه به دلیل ادعاهای کلاهبرداری از همان ابتدا با چالش‌های متعددی مواجه بوده‌است. ضررهایی که به خاطر کلاهبرداری وارد می‌شود بر تمام طرف‌های درگیر تاثیر می‌گذارد. حتی یکی از تقلب‌های کشف نشده می‌تواند منجر به زیان عظیمی شود [‏ ۳ ]‏؛ در نتیجه باعث افزایش هزینه‌های حق بیمه، ناکارآمدی فرآیند و از دست رفتن اعتماد می‌شود. اگرچه همه شرکت‌های بیمه سیستم‌های کشف را در محل دارند، اما هنوز اکثر این فرآیندها بسیار ناکارآمد و وقت گیر هستند. مکانیزم‌های سنتی به شدت بر مداخله انسانی تکیه می‌کنند و از این رو در صورت نیاز با هیچ تغییر یا وضعیتی سازگار نیستند. تحقیقات طولانی‌مدت منجر به تاخیر در پرداخت‌ها می‌شود و تاثیر منفی بر مشتری دارد. ادعاهای کلاهبردارانه، نه تنها سودآوری شرکت را مختل می‌کنند، بلکه سایر بیمه‌شوندگان را تشویق به نشان دادن رفتار مشابه می‌کنند. تقلب بیمه زمانی رخ می‌دهد که افراد تلاش می‌کنند با عدم تحقق شرایط قرارداد بیمه از آن سود ببرند [‏ ۱ ]‏. کلاهبرداری‌ها را میتوان تحت کلاه برداری نرم یا کلاه برداری سخت دسته‌بندی کرد [‏ ۴ ]‏. اگر یک بیمه شده عمدا یک تصادف را برنامه‌ریزی کند یا فقط برای به دست آوردن سود از شرکت بیمه خسارت وارد کند، در این صورت گفته می‌شود که این یک تقلب سخت است. با این حال، هنگامی که یک جراحت یا سرقت واقعی رخ می‌دهد، و بیمه‌شده در ادعای به دست آوردن پول بیشتر از شرکت اغراق می‌کند، پس آن را تقلب نرم می‌نامند. ​

تکامل کلان داده ها و رشد داده بدون ساختار باعث شده‌است که کلاهبرداران زیادی از سیستم سوء استفاده کنند. اگر داده‌ها به طور کامل تجزیه و تحلیل نشوند، احتمال وقوع تقلب بسیار زیاد خواهد بود [‏ ۳ ]‏. ​

داده کاوی و تجزیه و تحلیل، سناریوی تشخیص تقلب را تغییر داده‌است [‏ ۲ ]‏. داده‌ها می‌توانند از منابع مختلف جمع‌آوری شوند و برای استفاده بیشتر در یک مخزن ترکیبی ذخیره شوند. اجرای راه‌حل‌های تحلیلی برای سرمایه‌گذاری اولیه برای شرکت‌های بیمه هزینه دارد؛ از این رو همیشه در برابر اجرای آن مقاومت می‌کنند. با این حال، مشاهده شده‌است که استفاده از یادگیری ماشین و قابلیت‌های تحلیلی چرخه عمر بیمه را در بسیاری از اشکال تقویت کرده‌است. ​

این قادر بوده‌است تا با صرفه‌جویی در مقدار زیادی پول، با کاهش هزینه کلی تشخیص تقلب و بهبود بازگشت سرمایه بالای تشخیص تقلب، مزایای هزینه‌ای زیادی را برای شرکت‌ها فراهم کند. ​

بنابراین، لازم است که بیمه گران شروع به اعمال نفوذ در قابلیت درامد خودکار خود به منظور ایجاد سیستم‌های قوی‌تر و بدون ریسک کنند. از این رو، نیاز ضروری به توسعه سیستمی وجود دارد که بتواند به صنعت بیمه برای شناسایی کلاهبرداری‌های بالقوه با دقت بالا کمک کند، به طوری که ادعاهای دیگر را بتوان به سرعت رفع کرد در حالی که موارد شناسایی‌شده را می توان با جزئیات بررسی کرد. ​

مجموعه داده مورد استفاده در این مطالعه دارای یک مشکل عدم توازن کلاس است؛ یعنی تعداد نمونه‌های یک طبقه (‏مثبت) ‏از تعداد نمونه‌های طبقه دیگر (‏منفی) ‏فراتر می‌رود. سایر کلاس‌ها به عنوان کلاس اکثریت نامیده می‌شوند [‏ ۱۳ ]‏. به همین دلیل، کلاس اقلیت تمایل دارد در طول فرآیند طبقه‌بندی نادیده گرفته شود. برای اجتناب از نمونه‌های داده اقلیت که به عنوان نویز در نظر گرفته می‌شوند و طبقه‌بندی کننده که با نمونه اکثریت مغرضانه عمل می‌کند، این موازنه داده باید صورت گیرد. یک راه ساده برای رفع این عدم توازن، توازن مجموعه داده‌ها است، چه با نمونه‌های نمونه‌گیری بیش از حد طبقه اقلیت و چه با نمونه‌های نمونه‌گیری کم‌تر از طبقه اکثریت. ​

این مقاله پژوهشی با هدف توسعه مدلی برای کمک به بیمه کنندگان در گرفتن تصمیمات فعال و تجهیز آن‌ها برای مبارزه با تقلب انجام شده‌است. در این مقاله، ما روشی را برای تشخیص تقلب خودکار با استفاده از تکنیک طبقه‌بندی جنگل تصادفی ارائه می‌دهیم، که قبل از آن عدم توازن کلاس مجموعه داده اصلی خود را حذف می‌کنیم. این کار با استفاده از تکنیک بیش نمونه‌گیری اقلیت مصنوعی (‏SMOTE) ‏انجام می‌شود. ​

این مقاله به صورت زیر سازماندهی شده‌است. بخش 2، مروری کوتاه بر تحقیقات گذشته انجام‌شده در این زمینه، همراه با مجموعه داده‌ها ، نرم‌افزار مورد استفاده ارائه می‌شود. بخش ۳ روش پیشنهادی را توصیف می‌کند. بخش ۴ شامل نتایج و بحث ها است. بخش ۵ شامل تجزیه و تحلیل مقایسه‌ای رویکرد ما با دیگر مدل‌ها است. در بخش ۶ نتیجه‌گیری ارائه شده‌است که پس از آن لیستی از مراجع ارائه شده‌است. ​

### 2. مطالعات مرتبط  

​پیشرفت‌های مختلفی در حوزه تشخیص تقلب از دهه گذشته وجود داشته‌است. برخی از مطالعات مشابه عبارتند از: 

Subudhi و همکاران، مدلی را برای سیستم تشخیص تقلب بیمه خودکار (‏AIFDS) ‏با استفاده از روش بیش نمونه‌گیری تطبیقی (‏ADASYN) ‏برای مطالعه تاثیر درجه پیچیدگی (‏چولگی) ‏بر روی یک مجموعه داده ارائه کردند [‏ ۵ ]‏. ثابت شده‌است که استفاده از تکنیک‌های یادگیری ماشین می‌تواند دقت تشخیص تقلب در نمونه‌های نامتوازن را بهبود بخشد. ​

روش‌های گروهی متعددی نیز بر روی مجموعه داده‌های بیمه اجرا شده‌اند تا موارد کلاهبردارانه را شناسایی کنند. در [‏ ۱۱ ]‏، دسترسی شبکه عصبی همراه با روش زیرفضای تصادفی برای انجام تشخیص تقلب بیمه مورد استفاده قرار گرفت. Viaene و همکارانش [‏ ۶ ]‏ یک طبقه‌بندی کننده Boosting - Naive - Bayesian را برای تشخیص تقلب به کار بردند. این مدل مزایای تقویت و قدرت یک ساختار امتیاز بندی وزن را به اشتراک گذاشت. Omar و همکاران یک رویکرد مقرون‌به‌صرفه برای طراحی AIFDS ارائه دادند تا اسناد جعلی را از اسناد قانونی جدا کنند [‏ ۷ ]‏. ​

یک نظرسنجی از بیش از ۸۰ مقاله تحقیقاتی و مجله برای بررسی تمام رویکردهای یادگیری ماشین و پیشرفت‌هایی که در دهه گذشته ایجاد شده بود، انجام شد. این تحقیق نشان داد که شبکه‌های عصبی مصنوعی، SVM، Naive Bayes، جنگل تصادفی و KNN بیش‌ترین طبقه‌بندی کننده‌های مورد استفاده برای تشخیص تقلب بیمه اتومبیل بودند [‏ ۸ ]‏. تلاش در جهت کاهش زیان‌های مالی ناشی از سیاست‌های تقلب‌ها صورت‌گرفته است. فاز آزمایش این مطالعه، نشان می‌دهد که جنگل‌های تصادفی از دقت طبقه‌بندی کننده‌های J48 و Naive Bayes بهتر عمل می‌کنند و ثابت شده‌است که یک انتخاب مناسب برای تشخیص تقلب است. یافته این مطالعات، انگیزه‌ای برای این تحقیق بود. ​

**الف. نرم‌افزار استفاده‌شده** 

​**نرم‌افزار داده‌کاوی Weka:**  Wekaیک نرم‌افزار آزاد و اپن سورس است که به عنوان یک ابزار داده کاوی برای یادگیری ماشین و کشف دانش استفاده می‌شود. Weka توسط محققان مختلف استفاده می‌شود و می‌تواند برای توسعه طرح‌های یادگیری ماشین جدید از مجموعه داده‌های مختلف مهم باشد. مجموعه داده‌ها در Weka در قالب .arff و .csv بارگذاری می‌شوند. ما از این ابزار برای آزمایش مدل پیشنهادی خود تحت مجوز عمومی همگانی گنو(GNU) استفاده می‌کنیم. ​ 

**ب. توضیحات مجموعه داده** 

​مجموعه داده مورد استفاده که برای تحقیق ما استفاده می‌شود مجموعه داده بیمه اتومبیل "carclaims.txt" است که توسط نرم‌افزار “Angoss Knowledge Seeker” فراهم شده‌است [‏ ۱۲ ]‏. این داده‌ها در سال ۱۹۹۶ - ۱۹۹۴ در ایالات‌متحده ثبت شد. ​

این مجموعه داده شامل ۱۵۴۲۰ رکورد ادعای بیمه اتومبیل است که از این تعداد ۱۱،۳۳۸ رکورد از ژانویه ۹۴ تا دسامبر ۱۹۹۵ جمع‌آوری شده‌است و ۴۰۸۳ مورد باقی مانده در سال ۱۹۹۶ ثبت شده‌است. هر رکورد در مجموعه داده دارای ۳۳ ویژگی در کل است که به هنگام ادعاهای بایگانی ارائه شده‌اند. از میان این ۳۳ ویژگی، ۳۲ ویژگی ادعا هستند که به پیش‌بینی ۱ متغیر آخر، که برچسب کلاس نامیده می‌شود، کمک می‌کنند. ​

FraudFound: "متغیر هدف" ما است و نشان‌دهنده حضور و عدم وجود ادعای کلاهبرداری است. 

- کلاهبرداری برابر با ۱ است؛ 
- و غیر کلاهبرداری برابر با ۰ است. ​

توصیف آماری کامل مجموعه داده‌ها در جدول ۱ ارائه شده‌است. ​

جدول ۱: پوشش بیمه CAR [‏ ۱۲ ] 

|آمار داده‌ها|
| ---|--- |
|تعداد سوابق ادعا|۱۵۴۲۰ |
|تعداد ویژگی‌ها|۳۳|
|ویژگی‌های مطلق (‏اسمی) |25|
|ویژگی‌های عددی|6|
|تعداد ادعاهای عادی (‏غیر متقلبانه)‏ |۱۴،۴۹۷ (‏۹۴ %)‏|
|تعداد ادعاهای متقلبانه|۹۲۳ (‏۶ %)|
|تعداد سال‌های داده |3|
|ادعاهای متوسط (‏در هر ماه)|430|
مجموعه ویژگی کامل (‏یا برچسب‌های کلاس)‏ مجموعه داده شامل ۳۳ ویژگی در شکل ۱ توصیف شده‌است. ​

این مجموعه داده یک توزیع کلاسی نامتوازن است زیرا تقریبا ۹۴ % از ادعاهای غیرکلاهبرداری و تقریبا ۶ % از ادعاهای کلاهبرداری را دارد. ​
![](i0.png)

شکل 1. توصیف ویژگی مجموعه داده  [‏ ۱۲ ]

### 3. روش پیشنهادی  

ما مدلی را پیشنهاد می‌کنیم که هدف آن تسهیل تصمیم‌گیری بهتر بیمه‌ها در حین تصمیم‌گیری‌های مربوط به ادعا است. ​

رویکرد پیشنهادی با هر داده زمان واقعی با وجود چولگی کلاس - توزیع آن کار خواهد کرد زیرا ما مجموعه داده اصلی را به یک مجموعه داده متوازن قبل از انجام هر نوع الگوریتم طبقه‌بندی بر روی متغیر تبدیل می‌کنیم. ​

در این مقاله، تکنیک بیش نمونه‌گیری اقلیت مصنوعی (‏SMOTE) ‏برای توازن داده‌ها که توسط طبقه‌بندی کننده جنگل‌ها ی تصادفی دنبال می‌شود، به کار گرفته می‌شود تا رکوردها را به ادعاهای مخرب یا واقعی طبقه‌بندی کند. ​

روش پیشنهادی در مراحل زیر توصیف شده‌است. ​

**مرحله ۱: پیش‌پردازش داده‌ها** 

الف)‏ پاکسازی داده‌ها 

- پس از آپلود مجموعه داده، داده‌ها برای هر مقدار از دست رفته، داده‌های اضافی، تکراری‌ها یا هر گونه نویز موجود بررسی شدند. ​
- مجموعه داده اصلی carads.txt هیچ مقدار از دست رفته‌ای نداشت. ​

ب)‏ تبدیل داده ​

- برگه ثبت مطالبات به ترتیب شامل ۴ ستون برای سال، ماه، هفته ماه و روز هفته بود. ​
- این مقادیر را به صورت دستی به فرمت زمان - تاریخ نرمال به صورت YYYY - MM - DD تبدیل کردیم تا محاسبات را تسهیل کنیم. ​

ج)‏مصورسازی داده‌ها 

- ​داده‌ها به طور کامل با رسم نمودارهای مختلف تجزیه و تحلیل شدند و ویژگی‌ها با توجه به دسته‌هایشان گروه‌بندی شدند تا بینش بیشتری از آن به دست آورند. 
- این کار برای یافتن وابستگی‌های بین ویژگی‌های مختلف مجموعه داده بیمه انجام شد. ​
- ما گراف‌های دسته‌های زیر را برای بررسی همبستگی آن‌ها رسم کردیم: 
- تاخیر بین تاریخ حادثه و تاریخ ادعا 
- ​سن PolicyHolders در برابر FraudFound  
- نقص دارنده بیمه نامه یا شخص ثالث در مقابل FraudFound 

د)‏ بازیابی داده‌ها یا توازن داده‌ها (‏با استفاده از SMOTE) 

- نمونه‌گیری بیش از حد با استفاده از فیلتر SMOTE با حفظ مقدار کلاس = ۰ بدون تغییر انجام شد. 

**مرحله ۲: طبقه‌بندی داده‌ها (‏با استفاده از جنگل‌های تصادفی**) 

- استفاده از الگوریتم طبقه‌بندی جنگل‌های تصادفی با یک اندازه دسته‌ای ۱۰۰ و seedValue =1. ​
- روش‌ اعتبار سنجی متقابل ۱۰ فولد برای اجرای مدل به کار گرفته شد. ​

**مرحله ۳:مدل آموزش و تست** 

- اجرای مدل در مجموعه آموزش-آزمایش که به نسبت ۸۰ – ۲۰ در مجموعه داده قرار دارد. ​

**مرحله ۴: اعتبار سنجی مدل** 

- اعتبار سنجی نتایج تولید شده توسط ماتریس سردرگمی. ​

معماری مدل پیشنهادی در شکل ۲ نشان‌داده شده‌است.

اعمال طبقه‌بندی کننده جنگل های تصادفی

ارزیابی مدل

عرضه مجموعه تست

شناسایی داده های پرت

طبقه‌بندی داده

پیش‌پردازش داده

پاکسازی داده

انتقال داده

نمونه‌گیری مجدد مجموعه داده [‏ استفاده از تکنیک بیش نمونه‌گیری اقلیت مصنوعی (‏SMOTE)‏]

آپلود مجموعه داده‌های آموزشی

![](im0.png)

شکل ۲. معماری پیشنهادی برای سیستم تشخیص تقلب بیمه خودکار

**الف. حذف عدم توازن کلاس  در مجموعه داده با استفاده از تکنیک بیش نمونه‌گیری اقلیت مصنوعی (‏SMOTE)** 

تکنیک‌های مختلفی برای توازن داده‌ها وجود دارند که برای غلبه بر مشکل عدم توازن کلاس مورد استفاده قرار می‌گیرند؛ به طور گسترده به دو دسته نمونه‌گیری بیش از حد و نمونه‌گیری کم‌تر از حد تقسیم می‌شوند.    (‏شکل ۳) 

![](im1.png)
شکل 3. رسیدگی به توزیع نامتوازن کلاس

تکنیک بیش نمونه‌گیری اقلیت مصنوعی (‏SMOTE)‏ برای پر کردن مجموعه داده‌ها در رویکرد پیشنهادی ما مورد استفاده قرار می‌گیرد. SMOTE یک تکنیک شناخته‌شده نمونه‌گیری بیش از حد است، یک مجموعه داده نامتوازن را برای ایجاد یک مجموعه داده متوازن تغییر می‌دهد. کلاس اکثریت و نمونه‌های کلاس اقلیت را به طور مساوی توزیع می‌کند. SMOTE نمونه‌های مصنوعی یا نمونه‌های مشابه از کلاس اقلیت را ایجاد می‌کند و هدف آن کاهش بایاس پیش‌بینی طبقه‌بندی کننده نسبت به کلاس اکثریت است [‏ ۶ ]‏. ​

نمونه‌ها با توجه به الگوریتم k - نزدیک‌ترین همسایه تولید می‌شوند (‏شکل ۴)‏، که در آن هر همسایه از k نزدیک‌ترین همسایه به صورت تصادفی انتخاب می‌شود و در امتداد پاره خط (های) که به هر یک یا همه نزدیکترین همسایگان کلاس اقلیت k می پیوندد درج می شود. [‏ ۱۵ ]‏ (‏شکل ۵.)‏ تعداد نمونه‌های جدید تولید شده به مقدار نمونه‌گیری بیش از حد مورد نیاز بستگی دارد. ​
![](it.png)

شکل 4. رویکرد SMOTE
![](i19.png)

شکل 5. تولید نمونه‌های مصنوعی
![](i20.png)

شکل 6. الگوریتم نمونه‌برداری مجدد SMOTE

**الف. دسته‌بندی کننده جنگل های تصمیم تصادفی** 

جنگل‌های تصادفی (‏RF)‏که به عنوان جنگل‌های تصمیم تصادفی نیز نامیده می‌شوند، یک الگوریتم یادگیری ماشین نظارت کننده مبتنی بر درخت است که می‌تواند هم برای مسائل طبقه‌بندی و هم برای مسائل رگرسیون مورد استفاده قرار گیرد. RF درخت‌های تصمیم‌گیری را براساس نمونه‌های داده انتخابی تصادفی ایجاد می‌کند، مقدار پیش‌بینی را از هر درخت دریافت می‌کند و بهترین راه‌حل را با فرآیند رای‌گیری انتخاب می‌کند (‏شکل ۷.). این یک شاخص واقعا خوب برای به دست آوردن ویژگی‌های مهم از مجموعه داده است. کشف فعالیت‌های متقلبانه یکی از کاربردهای گسترده تکنیک RF است. ​

  ![](im2.png)
شکل ۷. دسته‌بندی کننده جنگل های تصادفی

### 4. نتایج و بحث  

**الف. معیارهای ارزیابی** 

ارزیابی موفقیت یک مدل برای تعیین میزان مناسب بودن آن برای حل یک مساله خاص بسیار مهم است. حتی پیشرفت‌های اندک در عملکرد می‌تواند منجر به مزایای اقتصادی بزرگ شود. ​

مدل ما براساس عملکرد نسبی و همچنین عملکرد مطلق آن با توجه به معیارهای مختلف عملکرد مانند - دقت، حساسیت و اختصاصی بودن مقایسه خواهد شد. فهرستی از برخی معیارهای عملکرد رایج در جدول ۲ داده شده‌است. ​

جدول ۲: معیارهای عملکرد 
![](i32.png)

در حین ساخت یک مدل تشخیص، صرفه‌جویی در پیش‌گیری از زیان باید با هزینه هشدارهای اشتباه متوازن شود. این که آیا یک هشدار ایجاد خواهد شد یا نه به TN، TP، FP و FN بستگی دارد [‏ ۱۴ ]‏. به جدول ۳ مراجعه کنید. ​

جدول ۳: پیش‌بینی و تولید هشدار [‏ ۱۴ ]

 ![](i33.png)

**ب. نتایج تجربی** 

پس از بیش نمونه‌گیری در کلاس اقلیت با استفاده از فیلتر SMOTE (‏شکل ۸.)‏ ، تعداد نمونه‌ها به ۱۶،۳۴۳ افزایش یافت که در آن نمونه‌های کلاس اقلیت به ۱۸۴۶ افزایش یافت و تعداد نمونه‌های کلاس مثبت برابر با ۱۴،۴۹۷ بود. ​

تعداد کل نمونه‌ها: 

- در پایگاه‌داده نامتوازن = ۱۵۴۲۰ (‏شکل. 9). ​
- در مجموعه داده‌های متوازن = ۱۶۳۴۳ (‏شکل ۱۰) 
![](i34.png)

شکل 8. فیلتر SMOTE در Weka
![](i35.png)

شکل ۹. توزیع کلاس داده‌ها قبل از نمونه‌گیری مجدد با SMOTE در Weka
![](i36.png)

شکل 10. توزیع کلاس داده‌ها پس از نمونه‌برداری مجدد با SMOTE در Weka

تحلیل داده اکتشافی (‏EDA) ‏مجموعه داده ما نتایج زیر را به همراه داشت. به شکل ۱۱، ۱۲، ۱۳ و ۱۴ مراجعه کنید. ​

- ۸۲ درصد از موارد کلاهبرداری مربوط به خودروهای ۶ تا ۸ ساله بود. این ثابت می‌کند که خودروهای قدیمی بیشتر درگیر کلاهبرداری می‌شوند. ​
- ۹۹.۶ درصد ادعاهای کلاهبردارانه شاهدی ندارند در حالی که در مورد ادعاهای غیرکلاهبردارانه ۸۳ درصد آن‌ها با شاهد هستند. ​

![](i37.png)

شکل 11. تاخیر بین تاریخ حادثه و تاریخ ادعا
![](i38.png)

شکل 12. درصد کلاهبرداری و وابستگی آن به تاخیر
![](i39.png)

شکل 13. نقص دارنده بیمه نامه یا شخص ثالث
![](i40.png)

شکل 14. سن دارنده بیمه نامه در مقابل درصد کلاهبرداری

ما تکنیک طبقه‌بندی را بر روی مجموعه داده‌های متوازن شامل ۱۶۳۴۳ نمونه اعمال کردیم. مشخص شد که ۱۵۳۱۸ مورد به درستی طبقه‌بندی شده‌اند که ۹۳.۷۲ % کل مجموعه داده است. ماتریس سردرگمی در شکل ۱۵ نشان‌داده شده‌است. ​
![](i41.png)

شکل 15. ماتریس سردرگمی برای مدل پیشنهادی

دقت دقیق مدل پیشنهادی در جدول [‏ IV ]‏ با میانگین وزنی متناظر داده شده‌است. روش پیشنهادی به ما دقت ۹۹.۹ % را داد، که ثابت شد بهتر از سیستم‌های مختلف تشخیص تقلب موجود است. ​

جدول ۴: معیارهای عملکرد رویکرد پیشنهادی 
![](i42.png)

### 5. تجزیه و تحلیل مقایسه‌ای  

ما یک تحلیل نسبی و مقایسه‌ای دقیق بین مدل پیشنهادی خود و دیگر رویکردهای موجود مدل SMOTE - SVM، درخت تصمیم و طبقه‌بندی کننده‌های MLP انجام می‌دهیم. برای تحلیل مقایسه‌ای نتایج به جدول 5 مراجعه کنید. ​

مشاهده شده‌است که روش پیشنهادی کارایی بهتری نسبت به مدل‌های دیگر [‏ ۵ ]‏ از نظر حساسیت و همچنین عوامل دیگر به ما می‌دهد. مدل ما مدل‌های دیگری را نیز مانند [‏ ۵ ]‏ اجرا کرده‌است. ​

جدول 5: مقایسه مدل‌های مختلف با رویکرد پیشنهادی [‏ ۵ ] 

|معیارهای عملکرد (‏در %)|ماشین بردار پشتیبان (SVM)|درخت تصمیم‌گیری|پرسپترون چندلایه (MLP)|مدل پیشنهادی|
| - | - | - | - | - |
|صحت|58.41|57.39|74.98|94.33|
|حساسیت (‏یا مقدار یادآوری)|90.53|86.94|47.83|**99.9**|
|اختصاصی بودن|36.86|38.14|18.75|45.1|


### 6. نتیجه گیری 

ارزیابی یک مدل تشخیص کلاهبرداری براساس عوامل متعددی است. ما دریافتیم که، انتخاب الگوریتم و معیارهای عملکرد نقش کلیدی در ارزیابی مدل ایفا می‌کنند و نتایج مورد انتظار روش‌های پیشنهادی را تحت‌تاثیر قرار می‌دهند. توازن داده‌ها یک روش سودمند برای بهبود صحت پیش‌بینی طبقه‌بندی کننده‌ها بوده‌است. ​

استفاده از روش نمونه‌برداری مجدد SMOTE برای متوازن کردن توزیع کلاس و سپس اعمال طبقه‌بندی مربوطه به ما نتایج استثنایی داده‌است. مدل ما نسبت به سه دسته‌بندی کننده مختلف تحت نظارت، یعنی ماشین بردار پشتیبان (‏SVM)‏، درخت تصمیم‌گیری و پرسپترون چند لایه (‏MLP) ‏عملکرد بهتری داشته و دارای حساسیت ۹۹.۹ % می‌باشد. ساخت مدل 1.43 ثانیه طول کشید. ​

این مدل را می توان با استفاده از دیگر تکنیک‌های توازن داده‌ها یا دیگر طبقه‌بندی‌هایی که تحت‌تاثیر عدم توازن کلاس قرار نمی‌گیرند، در مطالعات آینده بهبود بخشید. ​


