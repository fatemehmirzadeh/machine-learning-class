
# shaqayeqsaffari.github.io
<div dir="rtl">
  
  با توجه به دیتاست covid که در پوشه ی data موجود است عملیات زیر را روی این دیتاست انجام دهید:
  - نرمالیزه کردن
  - مرتب سازی داده
  - حذف داده های یکسان و تکراری
  - بدست آوردن 5 ویژگی که کمترین اهمیت را دارند
  -  اجرای الگوریتم های find-s و ce و بیز و knn و کلاسترینگ و درخت تصمیم یکبار به صورت تصادفی و یک بار با الگوریتم id3
  - داده های زیر همگی به عنوان true برچسب گذاری خواهند شد و ترکیبات داده ای دیگر به عنوان false تمام ترکیبات داده ای که قابل کشف می باشد را بدست آورید.
  - الگوریتم های اجرا شده را با rappid minner نیست اجرا کنید و نتیجه ی خود را با آن مقایسه کنید
  - دیتاست در سایت kaggle ثبت شده است در صورتی که کد خود را در بخش notebook های kaggle ثبت کنید نمره ی اضافه دریافت خواهید کرد.
   <br/> 
  <br/> 

 <div dir="rtl">

 <br/> 
  <br/> 
  ابتدا دیتاست اولیه داده میشود
  <br/> 
  اولین کار حذف ستون age به عنوان ویژگی ای هست که دارای داده های میسینگ ولسو های زیادیست.
  <br/> 
  سپس ستون ایدی ها هم # حذف میشود چون بعدا مارا دچار مشکل میکند و  اضافه است.
  <br/> 
  حال سطر های تکراری حذف میشود
  <br/> 
با توصیف یا همون مرتب سازی میفهمیم که بعضی ویگی ها بیشتر از دو حالت دارن بنابراین میفهمیم  
   چون مقادیر ویژگی ها با حروف کوچک و بزرگ نوشته شدن باید این موارد با موارد درست جایگذاری بشن 
  <br/> 

  مقادیر میسینگ ولیو هم پیدا میکنیم و درستشون میکنیم

  حالا که مقادیر تنظیم شدن نمونه های تکراری حذف میشن
  <br/> 
   از لحاظ نرمالسازیم اکنون که داده ها پاک سازیم شدن و داده ها همه yes, no هستن دیگه واحد های اندازه گیری ها خودشون یچیزه و دیگه نیاز به تعویض نداره.
   البته بعضی روش ها که باید ۰ و ۱ بشن را باید عددی کنیم.
  <br/> 
حالا باید ویژگی های مشابه حذف بشن که ویژگی هایی که تو نمودار مقادیر تقریبا مساوی ای تو yes , no  دارند باید حذف بشن و  اینهارا حذف میکنیم

  <br/> 
  برچسبشونو تعیین مکنیم به عنوان کرونایی ها 
    <br/> 
  حالا اینها دیتای کرونادار بودن و برای ساخت دیتای بدون کرونایی ترکیب هایی که میشود ساخت رو به همین اندازه تعداد نمونه های کرونایی میسازیم که برای اینکه تقریبا همینقدر بشه و بعد  از ادغام کرونایی و بدون کرونایی حاصل از حذف داده های تکراری میشود داده بو،ن کرونا که چون میخوایم همینقد بشه ۲۵۰ تا اینا بشه پس اون اول ۱۰۰ تا داده ترکیبی درست میکنیم. ...البته تمام حالات را میتوان ساخت اما زمانبر میباشد
   
  <br/> 
        حالا الگوریتم ها پیاده میشنوند که از توابع کتابخانه هاشون استفاده میکنیم اکثرا.

 <br/> 
Finds
برای الگوریتم find s با توجه به اینکه فرضیه اولیه از اولین نمونه مثبت ایجاد میشود با بعد هم دیدن نمونه های مثبت دیگر تغییر میکند ما با نمونه هایی با برچسبی با مقدار ۱ کار میکنیم و بعد هم دونه دونه تک تک مقدار ویژگی های هر فرضیه جدید با توجه به نمونه مثبتی که مقدار ویژگیش از مقدار ان ویژگی در فرضیه متفاوته و دو حالت صفر و یک بیشتر نداریم پس ? میشود
  <br/> 
  Candidate eliminate
 با توجه به اینکه فرضیه محدودترین و عمومی ترین داریم پس با هر دو مورد شروع میکنیم و خب فرضیه عمومی با دیدن نمونه های منفی و فرضیه محدودترین با دیدن مثبت ها تغییر میکند و اینکه هر بار باید فرضیه عمومی ترین توجه کند به فرضیه محدود، پس ما ترکیبات مختلف رو هم باید در نظر بگیریم و در نهایت به جواب فرضیه خاص و عمومی میرسیم
  <br/> 
Candidate eliminate
 با توجه به اینکه فرضیه محدودترین و عمومی ترین داریم پس با هر دو مورد شروع میکنیم و خب فرضیه عمومی با دیدن نمونه های منفی و فرضیه محدودترین با دیدن مثبت ها تغییر میکند و اینکه هر بار باید فرضیه عمومی ترین توجه کند به فرضیه محدود، پس ما ترکیبات مختلف رو هم باید در نظر بگیریم و در نهایت به جواب فرضیه خاص و عمومی میرسیم

knn 
در این روش هم با k نزدیک ترین همسایه مقدار تشخیص های روش ما با مقدار واقعی بخش تست در خروجی داده میشود که نشون میده دقت هم 53 درصد شده
  <br/> 
روش id3 
در این روش هم از کتابخانه موجود دو بخش ترین و تست بررسی و دقت داده میشود
  <br/> 
روش k means
 در اینجا هم دو روش silhoytte و elbow برای تشخیص عدد k هست که یه روش elbow هست و با استفاده از کتابخونه امادش روش اعمال میشود و دقت بررسی میشود
</div>
 
