

الگوریتم C4.5

C4.5 يک معيار استاندارد در يادگيري ماشين است. الگوریتم های ID3 و C4.5 فضای فرضیه ای کاملی را جستجو میکنند و مشکل محدودیت فضای فرضیه ای را ندارند. بایاس های استقرایی این الگوریتم ها این است که همیشه درخت های کوچکتر را بر درخت های بزرگتر ترجیح میدهند انتخاب صفت در این الگوریتم ها بر اساس حداقل کردن مقياس اطلاعات در يک گره است. هر مسير از ريشه به سمت يک گره، نمايان¬گر يک قانون دسته¬بندی می¬باشد. 
الگوریتم C4.5 یک دسته‌بندی (classifier) را در قالب یک درخت تصمیم تولید می‌کند که دارای ۲ نوع گره است. یک گره به‌صورت برگ که یک دسته را مشخص می‌کند و یک گره تصمیم که آزمون‌هایی روی یک صفت انجام می‌دهد تا یک شاخه یا زیر درخت به ازای هر خروجی آزمون تولید می‌کند.
classifier چیست؟
واژه classifier مفهومی فراتر و کلی تر از کلاس را دارد که علاوه بر کلاس، واسط ها و انواع داده ای را نیز پوشش می دهد.
الگوریتم C4.5 بهینه شده الگوریتم ID3 می باشد که از قانون هرس بعدی بهره می برد و می تواند صفاتی را که داده های نویزی و مقدار و همچنین صفات گسسته ندارند، استفاده نماید. در C4.5 فرض بر این است که کل داده های آموزشی در داخل حافظه باشند.
به جهت ساخت درخت تصمیم، فرض می کنیم که مجموعه داده های آموزشی که دارای برچسب کلاس مربوطه و بردار ویژگی ها هستند، در دسترس می باشند. معیارهای گوناگونی برای تقسیم بندی گره ها در درخت تصمیم وجود دارد که از عمومی ترین آنها، معیار ضریب بهره اطلاعات است که در C4.5 به کار می رد.
درخت تصمیم بر پایه آنالیز داده های ورودی و برای یافتن یک ویژگی بر مبنای تصمیم گیری برای هر نود استفاده می شود. ویژگی های گوناگونی از داده در هر نود بررسی می شود و یک ویژگی که اگر انتخاب شود، باعث خواهد شد که بی نظمی (آنتروپی) کاهش یابد، گزینش می شود. مبنای فعالیت نیز بر این اساس ایجاد شده است.
تئوري بر اين اساس است که تعداد آزمون¬هايي که باعث مي¬شود يک نمونه جديد در داخل پايگاه داده، دسته¬بندی شود، حداقل گردد. بخش انتخاب صفت در C4.5 بر اين اساس است که پيچيدگي درخت تصميم به شدت وابسته به مقدار اطلاعاتي است که با آن صفت در ارتباطند. با انتخاب آن صفت، اطلاعات بيشتر از هر صفت ديگري،  جدا و تقسيم مي¬شوند. الگوريتم C4.5 دامنه دسته¬بندي را علاوه بر صفات قياسي در انواع صفات عددي نيز توسعه مي¬دهد. الگوريتم اصولا صفتي را که حداکثر درجه جداسازي بين دسته¬ها را دارد را انتخاب مي¬کند و درخت تصميم را بر اساس آن مي¬سازد.
توليد درخت تصميم اوليه از روي مجموعه داده¬اي، مهم¬ترين بخش الگوريتم C4.5 مي¬باشد. الگوريتم در نهايت يک دسته¬بند را در قالب يک درخت تصميم توليد مي¬کند که داراي 2 نوع گره است. يک گره بصورت برگ که يک دسته را مشخص مي¬کند و يک گره تصميم که آزمون¬هايي روي يک صفت انجام مي¬دهد تا يک شاخه يا زير درخت به ازاي هر خروجي آزمون توليد مي-کند.
روش ساخت درخت مشابه¬اي، بصورت بازگشتي به هر زير مجموعه از نمونه¬ها اعمال مي-شود. اين رويه  ادامه مي¬يابد تا زير مجموعه¬ها شامل نمونه¬هايي باشند که به يک دسته تعلق داشته باشند.
فرآيند ساخت درخت، يک فرآيند واحد نمي¬باشد. متاسفانه، مشکل پيدا کردن کوچکترين درخت تصميم از روي يک نمونه داده¬اي مساله¬اي NP-Complete است. بنابراين، بايد روش-هاي ساخت درخت غير عقب¬گرد باشند و بصورت حريصانه عمل نمايند.


الگوریتم C4.5 در داده کاوی به عنوان یک طبقه‌بندی درخت تصمیم استفاده می‌شود که می‌تواند برای تولید یک تصمیم، بر اساس نمونه خاصی از داده‌ها (پیش‌بینی‌کننده‌های تک متغیره یا چند متغیره) استفاده شود.
قبل از اینکه به سراغ برویم C4.5 در مورد Decision Trees  و نحوه استفاده از آنها به عنوان طبقه‌بندی کننده صحبت کنیم.

در مورد Decision Trees، ضروری است که گره به گونه ای تراز شود که با تقسیم به سمت پایین، آنتروپی کاهش یابد. این اساساً به این معنی است که هر چه تقسیم بندی بیشتر به درستی انجام شود، تصمیم گیری قطعی آسان تر می شود.
بنابراین، ما هر گره را در برابر هر احتمال تقسیم بررسی می کنیم(Information Gain Ratio) پس از تقسیم اگر آنتروپی گره بعدی کمتر از آنتروپی قبل از تقسیم باشد و اگر این مقدار در مقایسه با همه موارد آزمایشی ممکن برای تقسیم کمتر باشد، گره به خالص ترین اجزای خود تقسیم می شود.
هرس
درخت تصمیم زمانی که مجموعه داده بزرگ است و متغیرهای بیشتری وجود دارد که باید در نظر گرفته شوند، ساده نیست.  این جایی است که هرس مورد نیاز است. هرس به حذف شاخه‌هایی از درخت تصمیم‌مان اشاره دارد که احساس می‌کنیم نقش مهمی در فرآیند تصمیم‌گیری ما ندارند.
اگر در مثال play tennis روز را هم یک ویژگی در نظر بگیریم بر روی داده های آموزشی خطای 0 دارد اما ویژگی روز قابلیت پیشبینی ندارد و از روی اتفاقی که امروز افتاده نمی توان اتفاقات روز های آینده را پیش بینی کرد. این ویژگی gain یلی خوبی دارد اما خودش ویژگی خوبی نیست.
مفهوم هرس ما را قادر می سازد تا از برازش بیش از حد مدل رگرسیونی یا طبقه بندی جلوگیری کنیم به طوری که برای نمونه کوچکی از داده ها، خطاهای اندازه گیری در حین تولید مدل لحاظ نشود.
به همین دلیل از gain ratio  و split information استفاده میکنیم.
مراحل الگوریتم C4.5
1.	بررسی هر ویژگی همانند قبل ID3
2.	برای هر ویژگیa ، نسبت به دست آوردن اطلاعات نرمال شده از تقسیم بر روی a را پیدا میکنیم(همان split information)
3.	a را به عنوان ویژگی با بالاترین split information قرار می دهیم
4.	a را به عنوان یک گره تصمیم قرار میدهیم
5.	این کار را برای گره های بعدی نیز انجام داده و آن گره‌ها را به عنوان فرزندان گره اضافه میکنیم.
مزایای C4.5 نسبت به سایر سیستم های درخت تصمیم:
1.	این الگوریتم ذاتاً از فرآیند هرس یک گذر برای کاهش بیش از حد برازش استفاده می کند.
2.	با هر دو مقدار گسسته و پیوسته انجام پذیر است.
3.	C4.5 می تواند مسئله با داده های ناقص را به خوبی حل کند
همچنین باید در نظر داشته باشیم که C4.5 بهترین الگوریتم موجود نیست، اما مطمئناً در موارد خاص مفید است.

