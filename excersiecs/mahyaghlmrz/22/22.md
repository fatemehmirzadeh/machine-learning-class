<div dir="rtl">

  ### مفاهیم زیر را به صورت خلاصه بررسی کنید.
  -	Ovefitting: معادل مفهوم ازدحام در الگویتم ژنتیک می باشد.هنگامی رخ می دهد که یادگیری بیش از حد انجام شود و و داده ها را بیش ا حد یادگرفته باشد در این حالت الگوریتم با وجود خطای آموزش کم دارای خطای زیادی به ازای داده تست می باشد.
  -	Local minimum: مینیمم محلی جایی است که در روش های گرادیان کاهشی ممکن است علیرغم وجود مینیمم اصلی به عنوان جواب نهایی مسئله شناسایی شود با در نظر گرفتن یک پارامتر ممنتم می توان گام های مسئله را تنظیم کرد و از این مینیمم های محلی خارج شد. 
  -	Gradient descent: گرادیان کاهشی یک الگوریتم بهینه سازی است که در بسیاری از شبکه های عصبی بر این اساس عمل می شود.در واقع بر اساس شیب نمودار در هر نقطه متناسب با گام یادگیری به سمت کاهش خطا حرکت می کنیم.
  -	Eager and lazy learning: برای تقسیم بندی روش های یادگیری رویکردی در نظر گرفته می شود
  eager:الگوریتم های مشتاق یا الگوریتم های global سریعا بر اساس مثال های موجود فرضیه ای ساخته می شود و با ورود مثال جدید بر اساس فرضیه قبلی نتیجه تعیین می شود بنابراین فاز تست سریع است.
  lazy: الگوریتم های تنبل مانند knn تا زمانی که نمونه جدیدی وارد نشود وارد فاز train نمی شود. به این الگوریتم ها الگوریتم های local هم می گویند. همچنین این الگوریتم ها در فاز train سریعتر هست. 

 

</div>
