<div dir="rtl">
  
  ### با دیتاست جمع آوری شده از پیامک ها و دیتاست کلمات اسپم پیامک های فارسی به همراه الگوریتم بیز تصمیم گیری در مورد هر پیامک را داشته باشید.
  ابتدا داده ی مربوط به sms را باز می کنیم.
</div>
<br/>
  
  ![خواندن فایل smsها](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/1.jpeg)
  
<br/>
<div dir="rtl">
  داده ها به صورت دستی label زده شده است و درصد داده های مربوط به ham و spam مشخص شده است.
    در مرحله بعد ابتدا داده ها به صورت رندم مرتب و 90% داده ها به عنوان نمونه train و 10% داده ها به عنوان نونه test در نظر گرفته شده است.
</div>  

  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/2.jpeg)
  
<br/>
<div dir="rtl">
  میزان داده های ham و spam موجود در داده های train و test به صورت زیر می باشد.
</div>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/3.jpeg)
  
<br/>
<div dir="rtl">
  پس از آن کلمات موجود در داده ها تعیین و تعداد تکرار آن ها در هر سطر داده در یک لیست با عنوان vocabulary مشخص می شود.
</div>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/4.jpeg)
  
<br/>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/5.jpeg)
  
<br/>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/6.jpeg)
  
<br/>
<div dir="rtl">
  هدف این است که text detection با الگوریتم بیز صورت گیرد بنابراین نیاز است تا احتمالات شرطی مورد نیاز در الگوریتم naïve Bayes محاسبه گردد.
</div>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/7.jpeg)
  
<br/>
<div dir="rtl">
</div>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/8.jpeg)
  
<br/>
<div dir="rtl">
  در داده تست در صورتی که احتمال محاسبه شده برای ham یا spam بودن پیام بیشتر باشد به ترتیب دارای label، ham یا spam می شود.
</div>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/9.jpeg)
  
<br/>
<div dir="rtl">
</div>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/10.jpeg)
  
<br/>
<div dir="rtl">
    در نهایت میزان صحت این الگوریتم مشخص شده است.
</div>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/28/image/11.jpeg)
  
<br/>
<div dir="rtl">
  کد نهایی:
</div>

```
import pandas as pd

sms_spam = pd.read_csv('sms_data.csv', sep=',',usecols = ['sms', 'label'])

print(sms_spam.shape)
sms_spam.head()

sms_spam['label'].value_counts(normalize=True)

# Randomize the dataset
data_randomized = sms_spam.sample(frac=1, random_state=1)

# Calculate index for split
training_test_index = round(len(data_randomized) * 0.9)

# Split into training and test sets
training_set = data_randomized[:training_test_index].reset_index(drop=True)
test_set = data_randomized[training_test_index:].reset_index(drop=True)

print(training_set.shape)
print(test_set.shape)

training_set['label'].value_counts(normalize=True)

test_set['label'].value_counts(normalize=True)

# Creating the Vocabulary
training_set['sms'] = training_set['sms'].str.split()

vocabulary = []
for sms in training_set['sms']:
   for word in sms:
      vocabulary.append(word)

vocabulary = list(set(vocabulary))
len(vocabulary)

word_counts_per_sms = {unique_word: [0] * len(training_set['sms']) for unique_word in vocabulary}

for index, sms in enumerate(training_set['sms']):
   for word in sms:
      word_counts_per_sms[word][index] += 1

word_counts = pd.DataFrame(word_counts_per_sms)
#word_counts.head()

training_set_clean = pd.concat([training_set, word_counts], axis=1)
training_set_clean.head()


# Calculating Constants First

# Isolating spam and ham messages first
spam_messages = training_set_clean[training_set_clean['label'] == 'spam']
ham_messages = training_set_clean[training_set_clean['label'] == 'ham']
# P(Spam) and P(Ham)
p_spam = len(spam_messages) / len(training_set_clean)
p_ham = len(ham_messages) / len(training_set_clean)
# N_Spam
n_words_per_spam_message = spam_messages['sms'].apply(len)
n_spam = n_words_per_spam_message.sum()
# N_Ham
n_words_per_ham_message = ham_messages['sms'].apply(len)
n_ham = n_words_per_ham_message.sum()

# N_Vocabulary
n_vocabulary = len(vocabulary)

# Laplace smoothing
alpha = 1

# Calculating Parameters
# Initiate parameters
with open('spam.txt', 'r') as fd:
  spam_vocab = fd.read().split('\n')  

parameters_spam = {unique_word:0 for unique_word in spam_vocab}
parameters_ham = {unique_word:0 for unique_word in vocabulary}

# Calculate parameters
for word in vocabulary:
   n_word_given_spam = spam_messages[word].sum() # spam_messages already defined
   p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)
   parameters_spam[word] = p_word_given_spam

   n_word_given_ham = ham_messages[word].sum() # ham_messages already defined
   p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)
   parameters_ham[word] = p_word_given_ham


# Classifying A New Message
import re

def classify(message):
   '''
   message: a string
   '''

   message = re.sub('\W', ' ', message)
   message = message.lower().split()

   p_spam_given_message = p_spam
   p_ham_given_message = p_ham

   for word in message:
      if word in parameters_spam:
         p_spam_given_message *= parameters_spam[word]

      if word in parameters_ham: 
         p_ham_given_message *= parameters_ham[word]

   print('P(Spam|message):', p_spam_given_message)
   print('P(Ham|message):', p_ham_given_message)

   if p_ham_given_message > p_spam_given_message:
      print('Label: Ham')
   elif p_ham_given_message < p_spam_given_message:
      print('Label: Spam')
   else:
      print('Equal proabilities, have a human classify this!')

# Measuring the Spam Filter's Accuracy
def classify_test_set(message):
   '''
   message: a string
   '''
   message = re.sub('\W', ' ', message)
   message = message.lower().split()

   p_spam_given_message = p_spam
   p_ham_given_message = p_ham

   for word in message:
      if word in parameters_spam:
         p_spam_given_message *= parameters_spam[word]
      if word in parameters_ham:
         p_ham_given_message *= parameters_ham[word]

   if p_ham_given_message > p_spam_given_message:
      return 'ham'
   elif p_spam_given_message > p_ham_given_message:
      return 'spam'
   else:
      return 'needs human classification'

test_set['predicted'] = test_set['sms'].apply(classify_test_set)
test_set.head()


correct = 0
total = test_set.shape[0]

for row in test_set.iterrows():
   row = row[1]
   if row['Label'] == row['predicted']:
      correct += 1

print('Correct:', correct)
print('Incorrect:', total - correct)
print('Accuracy:', correct/total)

```

  
  </div>
