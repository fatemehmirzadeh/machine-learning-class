<div dir="rtl">
  
  ###   سعی کنید دسته بندی هر خبر را به صورت خودکار بدست آورید.
</div>
<br/>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/30/image/1.jpeg)
  
<br/>
<div dir="rtl">
  داده ها به صورت دستی label زده شده است و درصد داده های مربوط به ham و spam مشخص شده است.
    در مرحله بعد ابتدا داده ها به صورت رندم مرتب و 90% داده ها به عنوان نمونه train و 10% داده ها به عنوان نونه test در نظر گرفته شده است.
</div>  

  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/30/image/2.jpeg)
  
<br/>
<div dir="rtl">
  میزان داده های ham و spam موجود در داده های train و test به صورت زیر می باشد.
</div>
  
  ![](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/mahyaghlmrz/30/image/3.jpeg)
  
<br/>
<div dir="rtl">
  کد نهایی:
</div>

```
import pandas as pd 
import matplotlib.pyplot as plt
from sklearn.feature_extraction import text
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

data = pd.read_csv("news_data1.csv",error_bad_lines=False,usecols =["headline_text"])

# Randomize the dataset
data_randomized = data.sample(frac=1, random_state=1)

# Calculate index for split
training_test_index = round(len(data_randomized) * 0.9)

# Split into training and test sets
training_set = data_randomized[:training_test_index].reset_index(drop=True)
test_set = data_randomized[training_test_index:].reset_index(drop=True)

with open('stop-word.txt', 'r') as fd:
  stop_words_list = fd.read().split('\n') 
stop_words =frozenset(stop_words_list)

desc = training_set['headline_text'].values
vectorizer = TfidfVectorizer(stop_words = stop_words)
X = vectorizer.fit_transform(desc)
word_features = vectorizer.get_feature_names()

kmeans = KMeans(n_clusters = 3, n_init = 20) # n_init(number of iterations for clsutering) n_jobs(number of cpu cores to use)
#kmeans.fit(X)
kmeans.fit_predict(X)
common_words = kmeans.cluster_centers_.argsort()[:,-1:-26:-1]
for num, centroid in enumerate(common_words):
    print(str(num) + ' : ' + ', '.join(word_features[word] for word in centroid))

descTest = test_set['headline_text'].values
Y = vectorizer.transform(descTest)
kmeans.predict(Y)

```

  
  </div>
