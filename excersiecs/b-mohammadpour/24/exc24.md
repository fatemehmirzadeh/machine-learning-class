## تاریخچه پیدایش تئوری بیز
<div dir="rtl">
  در نیمه دوم قرن ۱۸، هنوز شاخه ای از ریاضیات به نام آمار و احتمال بوجود نیامده بود. در نتیجه بیشتر قضیه ها و تئوری های احتمال توسط ریاضیدانان شناخته و اثبات میشد. به این ترتیب اصول و قضیه های احتمال را الگوهای شانس (Doctrine of Chances) می نامیدند زیرا در کتابی که توسط دمویر (Abraham de Moievre) نوشته شده بود، او از این اصطلاح استفاده کرده بود. در مقاله ای با نام «روش های محاسبات در الگوهای شانسی» (An Essay towards solving a Problem in the Doctrine of Chances) که توسط بیز در سال 1763 نوشت و توسط دوستش ریچار پرایس (Richard Price) منتشر شد نیز به بررسی شیوه محاسبه احتمال برای پدیده های شانسی و تصادفی پرداخته شده است.

او در این مقاله که به نظر ساده می آمد، احتمال توام، احتمال شرطی و احتمال حاشیه ای را مطرح کرد و به کمک آنها عکس قضیه احتمال شرطی را ارائه داد.

از آن به بعد بین دو گروه از پیروان مکتب «احتمال برمبنای فراوانی» (Probability Bases on Frequency) و  «احتمال برمبنای بیز» (Bayesian Probability) اختلاف نظر و درگیری های زیادی بوجود آمده است. ولی بهتر است به دور از این اختلاف نظرها به منطق و دستآورد قضیه بیز بپردازیم.

اگر A و B دو پیشامد از فضای نمونه باشند، آنگاه میتوان احتمال A به شرط B را برحسب احتمال B نوشت. این رابطه در زیر دیده میشود.
<br/>
    P(h│D)=  (P(D│h)P(h))/(P(D))
<br/>
## مزایا ومعایب
 <br/>
پیش بینی کلاس مجموعه داده های آزمون آسان و سریع است. همچنین با فرض استقلال ویژگی ها در پیش بینی های چند طبقه ای عملکرد خوبی دارد، یک طبقه بندی Naive Bayes در مقایسه با سایر مدلها مانند رگرسیون لجستیک عملکرد بهتری دارد و الگوریتم به داده های آموزشی کمتری نیاز دارد. برای متغیر عددی، توزیع نرمال فرض میشود (منحنی زنگوله، که یک فرض قوی است).
 <br/>
معایب الگوریتم دسته بندی بیز ساده Naive Bayes :  این الگوریتم در مورد مقادیر طبقه ای بهتر از مقادیر عددی عمل میکند. همچنین، اگر یک متغیر دسته بندی در مجموعه داده های آزمون، دسته ای داشته باشد که در مجموعه داده های آموزش وجود نداشته باشد، مدل به آن احتمال صفر میدهد و قادر به پیش بینی نخواهد بود. به این مسئله مشکل فرکانس صفر گفته میشود. محدودیت دیگر Naive Bayes فرض پیش بینی های مستقل است. در زندگی واقعی، تقریباً غیرممکن است که مجموعه ای از پیش بینی کننده ها را کاملاً مستقل بدست آوریم.

بی اثر کردن الگوریتم دسته بندی بیز ساده Naive Bayes روشی است که توسط اسپمرهای ایمیل استفاده می شود تا سعی در کاهش کارآیی فیلترهای هرزنامه ها داشته باشد که از قانون Bayes استفاده می کنند. این روش با تبدیل کلماتی که قبلاً به کلمات اسپم در یک پایگاه داده بیزی شناخته می شده اند به کلماتی که نشانه ی اسپم بودن را ندارد و یا افزودن کلماتی که احتمالاً در ایمیل های غیر هرزنامه وجود دارد، این فیلتر را کم اثر کنند. با این حال، آموزش مجدد فیلتر به طور موثری از انواع حملات جلوگیری می کند. به همین دلیل است که از الگوریتم دسته بندی بیز ساده Naive Bayes به همراه اکتشافات خاص مانند لیست سیاه همچنان برای شناسایی هرزنامه استفاده می شود.  
</div>
  
