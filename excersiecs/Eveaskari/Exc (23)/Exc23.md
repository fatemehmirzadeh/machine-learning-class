<div dir="rtl">
  
 ###  تفاوت های k=1 ، k=5 را در یک داده ی فرضی با الگوریتم knn بررسی کنید. 
  
  <br/>
  الگوریتم k-nn : فرض میکنیم فضای داده ای داریم و یک نمونه داریم که میخواهیم بدانیم این نمونه به کدام یک از همسایگانش شباهت دارد. ما نزدیک ترین همسایه ها را برای نمونه مان انتخاب میکنیم.
  <br/>
  حال اینکه تعداد همسایگان چه تعداد باشد مسئله است.
  اگر ما کل فضای نمونه را برابر تعداد همسایگان قرار دهیم معنی همسایگی را زیر سوال برده و دچار خطای بالا برای انتخاب جواب درست میشویم.
  <br/>
  تعداد همسایگان یا k  همیشه یک عدد فرد است تا در مقایسات یک برنده داشته باشیم و به تساوی نرسیم . k  = 1, 3 , 5 ,...
  <br/>
  در انتخاب 1nn وقتی میخواهیم نمونه ها را مقایسه کنیمچون فقط یک همسایه وجود دارد جواب را همان انتخاب می کنیم که ممنکن است منجر به خطا شود.مثلا اگر  نمونه ای + داشته باشیم و  همسایه اش - باشد برای آن نمونه جواب منفی را به ما میدهد که اشتباه هست.
  <br/>
  حال فرض کنید شعاع همسایگی را بیشتر کنیم . مثلا 5nn .در این حالت نمونه ما برای به جواب رسیدن 5 همسایه خود را مقایسه میکند و هر کدام که مقدار بیشتری داشت را به عنوان جواب میگیرد.
  <br/>
  مثلا در یک همسایگی 3 داده + و 2 داده - داشته باشیم برای نمونه ما جواب + می شود باتوجه به بیشتر بودن همسایگان +
  <br/>
  اگر بخواهیم در همسایگی نصبت تاثیر را هم در نظر بگیریم ممکن است به جواب متفاوتی برسیم
  <br/>
  در مثال قبل اگر 3 همسایه مثبت از نمونه دور و 2 همسایه منفی به نمونه نزدیک میبود دیگر تاثیر مثبت ها از منفی ها کتمر میشد و احتمالا جواب منفی میشد.
  <br/>
  پس میتوان در بعضی مسائل وزن همسایگان را هم به عنوان عامل موثر در انتخاب جواب دانست
  <br/>
  البته دراینجا منظور از نزدیکی و همسایگی مقدار شباهت داده هاست و اینکه چه چیزی معیار شباهت ماست مهم است. و منظور از فاطله دور یا نزدیک فاصله هندسی نیست و فاصله همان مقدار شباهت است.
  <br/>
  
  <br/>
  
  
  <br/>
  </div>
