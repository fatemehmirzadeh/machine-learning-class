
<div dir="rtl">
  
  #### 24)  تاریخچه پیدایش تئوری بیز را بررسی کنید و مزایا و معایب این تئوری را بررسی کنید.
  
  <br/>
  
قضیه بیز : نام این قضیه به افتخار دانشمند انگلیسی آمار توماس بیز (Thomas Bayes)،  که در سال 1763 مقاله ای با این موضوع منتشر کرد، انتخاب شده است. روشی برای دسته بندی پدیده ها، بر پایه احتمال وقوع یا عدم وقوع یک پدیده است و در نظریه احتمالات با اهمیت و پرکاربرد است. اگر برای فضای نمونه ای مفروضی بتوانیم چنان افرازی انتخاب کنیم که با دانستن اینکه کدامیک از پیشامدهای افراز شده رخ داده است، بخش مهمی از عدم قطعیت تقلیل می یابد.
این قضیه از آن جهت مفید است که می توان از طریق آن، احتمال یک پیشامد را با مشروط کردن نسبت به وقوع یا عدم وقوع یک پیشامد دیگر محاسبه کرد. در بسیاری از حالت ها، محاسبهٔ احتمال یک پیشامد به صورت مستقیم کاری دشوار است. با استفاده از این قضیه و مشروط کردن پیشامد مورد نظر نسبت به پیشامد دیگر، می توان احتمال مورد نظر را محاسبه کرد.
بدون شک قضیه بیز (Bayes Theorem) یکی از مهم ترین اصول آمار و احتمالات است که بخش قابل توجهی از دانش مدرن ما در حوزه های مختلف، به طور خاص در حوزه هوش مصنوعی و مهندسی کنترل، بر آن استوار است. پروازهای امن در خطوط هوایی، سیستم های نظارتی و کنترلی شبکه برق، روبات های متحرک، موتورهای جستجو و ده ها کاربرد دیگر در زندگی روزمره ما، بدون این قانون عملا نمی توانستند وجود داشته باشند. بخش قابل توجهی از دانش هوش مصنوعی، که وظیفه آن توسعه هوشمندی سیستم های کامپیوتری است، بر روی قانون بیز و آمار بیزی بنا شده است. به عقیده بسیاری از دانشمندان علوم کامپیوتر، اساسی ترین معادله توصیف کننده هوش، همین قانون بیز است.

روش بیز روشی برای دسته بندی پدیده ها، بر اساس احتمال وقوع یا عدم وقوع یک پدیده است. این روش یکی از ساده ترین الگوریتم های پیش بینی در جهان به شمار می رود و نکته مهم در مورد این الگوریتم این است که در عین سادگی دقت قابل قبولی هم دارد که هر دو از مزیت های آن به شمار می روند.
دقت این الگوریتم را می توان با استفاده از برآورد چگالی کرنل به صورت قابل توجهی بالا برد. شیوه یادگیری در روش بیز ساده از نوع یادگیری با نظارت است. این روش در دهه ١٩٦٠ در میان دانشمندان بازیابی اطلاعات توسعه یافت و هنوز هم از روش های محبوب در دسته بندی اسناد به شمار می آید.
امروزه برنامه های کاربردی بسیاری وجود دارند که پارامترهای مختلف مربوط به الگوریتم بیز ساده را تخمین می زنند، با استفاده از این ابزارها افراد بدون سروکار داشتن با تئوری بیز می توانند از این امکان در راستای حل مسائل مورد نظر بهره ببرند. با وجود مسائل طراحی و پیش فرض هایی که در خصوص روش بیز وجود دارد، این روش برای طبقه بندی کردن بیشتر مسائل در جهان واقعی، کاملا مناسب است.
برای دسته بندی کردن ساده و تعیین روشی برای تشخیص برچسب اشیا یا نقاط اکثر اوقات از تکنیک دسته بند بیز ساده استفاده می شود. در واقع، برای به کارگیری دسته بند بیز ساده، الگوریتم یکتایی وجود ندارد و در عوض خانواده ای از الگوریتم ها موجود است که با فرض استقلال ویژگی ها یا متغیرها نسبت به یکدیگر عمل می کنند.


ویژگی های بارز الگوریتم دسته بندی عبارتند از:
پیش بینی آنی (Real-time prediction): به خاطر پیاده سازی ساده و محاسبات سریع آن، می توانیم از آن برای پیش بینی های آنی استفاده کنیم.
پیش بینی چند کلاسی (Multi-class prediction): از الگوریتم طبقه بند  naïve bayesمی توانیم برای پیش بینی احتمال خلفی کلاس های متعدد متغیر هدف استفاده کنیم.
طبقه بندی متن (Text classification): با نگاهی دوباره به ویژگی پیش بینی چند کلاسی، می توان دریافت که الگوریتم های طبقه بندی Naive Bayes بسیار مناسب طبقه بندی متن هستند. به همین دلیل می توانیم از آنها برای حل مسائلی مانند spam-filtering و تحلیل احساسات استفاده کنیم.
سیستم پیشنهاد (Recommendation system): علاوه بر الگوریتم هایی مانند فیلتر کردن مشارکتی collaborative filtering)،(Naive Bayes یک سیستم پیشنهادی ایجاد می کند که می توانیم از آن برای فیلتر کردن اطلاعات غیر قابل دیدن و پیش بینی اینکه آیا یک کاربر منبع داده شده را دوست دارد یا خیر، استفاده کنیم.


از مزایای این روش می توان به موارد زیر اشاره کرد:<br/>
  
•	دسته بندی کردن داده های آزمایشی آسان و سریع است. همچنین زمانی که تعداد دسته ها از دو بیشتر باشد نیز عملکرد خوبی از خودش نشان می دهد.
<br/>
•	تا زمانی که شرط مستقل بودن برقرار باشد، یک دسته بندی کننده بیز ساده عملکرد بهتری نسبت به مدل های دیگر مانند رگرسیون لجستیک دارد و به حجم آموزش کمی نیاز دارد.
 <br/>
•	در حالتی که ورودی هایمان دسته بندی شده باشند این روش عملکرد بهتری نسبت به حالتی دارد که ورودی هایمان عدد باشند. برای حالتی که ورودی عدد باشد معمولاً فرض می شود که از توزیع نرمال پیروی می کنند. (که فرض قوی ای است)
<br/>
  در اعمال به داده هایی با حجم بالا صحت و سرعت بالایی دارد.اجرای راحت، نتایج خوب برای بسیاری از کاربردها،
  
معایب:
  <br/>
•	در صورتی که ورودی مان دسته بندی شده باشد و در مرحلهٔ یادگیری دسته ای وجود داشته باشد که دسته بندی کننده هیچ داده ای از آن دسته مشاهده نکرده باشد، دسته بندی کننده احتمالی برابر صفر برای آن دسته در نظر می گیرد و قادر به دسته بندی کردن نخواهد بود. برای حل این مشکل می توان از تکنیک های هموارسازی مانند تصحیح لاپلاس استفاده کرد.
 <br/>
•	یکی دیگر از معایب این دسته بندی کننده این است که دستیابی به شرط مستقل بودن در دنیای واقعی تقریباً غیرممکن است.
 <br/>
  
  استقلال شرطی دسته ها فرضی است که در اینجا مطرح شده است.
     اما در مواردی که این فرض برقرار نیست دقت مدل پایین است. در عمل وابستگی وجود دارد و فرض استقلال همواره برقرار نیست. نحوه برخورد با این وابستگی ها شبکه های بیزی می باشد.


   روش بیز کاملا  براساس محاسبات ریاضی است و از نظر دقت قابل قبول است و به صورت احتمالاتی جواب می دهد.
  در مساله مورد بررسی اگر تعداد ویژگی ها یکی باشد  مشکلی نداریم اما اگر بیش از یک ویژگی داشته باشیم در صورتیکه میزان تاثیرشان را روی یکدیگر بدانیم می تواند به حل مساله کمک کنند (حتما نیاز نیست ویژگی ها از یکدیگر مستقل باشند، ایده آل این است که مستقل باشند) و این موضوع باعث شده روش بیز روش نسبتا کم کاربردی در یادگیری ماشین گردد به خصوص وقتی تعداد ویژگی ها زیاد می شوند، ما هم معمولا با ویژگی های زیاد مساله را حل می کنیم و تاثیر ویژگی ها را بر هم نمی دانیم، روش بیز از نظر ریاضی قابل استفاده نیست.
  
  
  روش دیگری به نام بیز ساده (Naive Bayes) یک فرضی را برای حل مساله در نظر می گیرد و بااین فرض مساله را حل می کند، آن فرض این است که ویژگی ها از هم مستقل  هستند.  
  
