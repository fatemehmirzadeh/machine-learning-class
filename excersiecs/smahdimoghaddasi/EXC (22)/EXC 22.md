

<div dir="rtl">
  
  ### 22) مفاهیم زیر را به صورت خلاصه بررسی کنید.
  <br/>
  
  ### Ovefitting
  ### Local minimum
  ### Gradient descent
  ### Eager and lazy learning
  <br/><br/>
  
  ### Ovefitting:
  <br/>
  
  در شکل 1 خط (فرضیه) روی مثال های آموزشی نسبتا خوب جواب می دهد و
  در شکل 2 فرضیه روی تمامی نمونه های آموزشی فیت شده است، و اگر نمونه ی تستی وارد شود فرضیه ی 1  نسبت به 2 بهتر عمل می کند، چون منطق بهتری دارد و به عبارتی داده های 
   آموزشي را حفظ نکره است. 
   <br/>
  فرضیه ای که روی مثال های آموزشی خیلی خوب عمل می کند، اما در مثال های آزمایشی (داده های واقعی ) دقت اش کم تر است، 
  در اين حالت، فرضیه روی مثال های آموزشی overfit شده است
  و به مثال های آموزشی خیلی خیلی بها داده ايم.
 
  <br/>
  
  ### شکل 1
  
  ![22-1.jpg](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/smahdimoghaddasi/EXC%20(22)/22-1.jpg)
       
  ### شکل 2
  
   ![22-2.jpg](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/smahdimoghaddasi/EXC%20(22)/22-2.jpg) 
    
   <br/>
  
   <div dir="rtl">
   دو نوع خطای فرضیه داریم خطای آموزش که خطا روی داده های آموزش (error train) است و خطای اصلی که خطا در کل توزیع (error D) است 
    <br/>  
  error D خطا در کل توزیع (خطای اصلی) برای ما مهم تر از error train است.
  <br/>
  
  
  error train (h) < error train (h`)  <br/>
  
  error D (h) > error D (h`)
  <br/>
  <br/>
  <div dir="rtl">
   در آموزش h بهتر عمل کرده است اما `h بهتر است. 
   <div/>
  
   D= کل توزیع(همه ی نمونه ها)
   <br/>
     <div dir="rtl"> 
       overfitting وقتی اتفاق می افتد که آموزش بیش از اندازه انجام می دهیم، بطوریکه تعمیم پذیری شبکه دچار اختلال شود  یعنی شبکه یاد گرفته است برای داده هایی به جز آموزش خوب جواب دهد ولی اگر آموزش را ادامه دهیم از این حالت ممکن است دور شویم. 
   
 در شکل زیر میبینیم از یک جایی به بعد خطا زیاد شده است که همان جا باید trian شبکه متوقف گردد.
  <br/>
      
 ![22-3.png](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/smahdimoghaddasi/EXC%20(22)/22-3.png)
       
 ### Local minimum :  
       
 
در حالت ايده آل با تعيين يک نرخ يادگيري مناسب مي توان به خطاي حداقل رسيد ولي اگر نرخ يادگيري کم انتخاب شود، الگوريتم ممکن است در مينيمم هاي محلي گير کند 
(مينيمم محلي خواصي شبيه به مينيمم اصلي دارند و در اين مناطق نيز شيب خطا صفر است و الگوريتم به اشتباه فکر مي کند که به مقدار بهينه رسيده است)
و در نتيجه شبکه به درستي آموزش نمي بيند.
       
 ![22-4.png](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/smahdimoghaddasi/EXC%20(22)/22-4.png)
       
    

برای پرهیز از مینیمم محلی روشهای مختلفی وجود دارد:
       
افزودن ممنتم<br/>
استفاده از stochastic gradient descent
<br/>
استفاده ازشبکه های مختلف با مقادیر متفاوتی برای وزنهای اولیه

افزودن ممنتم:
می توان قانون تغییر وزن ها را طوری در نظر گرفت که تغییر وزن در تکرار n ام تا حدی به اندازه تغییر وزن در تکرار قبلی بستگی داشته باشد.
 <div/>
ΔWji (n) = η δj Xji + αΔWji (n-1)
<div dir="rtl">
    که در آن مقدارممنتم بصورت زیر می باشد:
           
0≤ α <1
        
<br/>     
افزودن ممنتم باعث می شود تا با حرکت در مسیر قبلی در سطح خطا:
<br/>
از گیر افتادن در مینیم محلی پرهیز شود
<br/>
از قرارگرفتن در سطوح صاف پرهیز شود
<br/>
با افزایش تدریجی مقدار پله تغییرات، سرعت جستجو افزایش یابد.
 <br/> 
  
  ### Gradient descent:
  <br/>
  
  
کاهش گرادیان (Gradient descent) الگوریتم بهینه سازی مرتبهٔ اول از نوع الگوریتم های تکرار شونده است. برای یافتن کمینهٔ محلی یک تابع با استفاده از این الگوریتم، گام هایی متناسب با منفی گرادیان (یا گرادیان تخمینی) تابع در محل فعلی برداشته خواهد شد.
 اگر در استفاده از این الگوریتم، گام هایی متناسب با جهت مثبت گرادیان برداشته شود، به بیشینهٔ محلی تابع نزدیک می شویم که به این فرایند افزایش گرادیان گفته می شود. 
اگر تابع محدب یا مقعر باشه به بیشینه سراسری می رسیم. بسیاری از مسائل یادگیری ماشینی محدب هستند و از اینرو گرادیان کاهشی جواب بهینه را در این مسائل تولید می کند.
<br/>
<br/>
پس انتشار خطا همراه با الگوریتم کاهش گرادیان وظیفه  پیدا کردن وزن های شبکه ی عصبی را برعهده دارد و این کار را با بازگشت لایه به لایه از خروجی به سمت ورودی انجام می دهد. منظور از پس انتشار هم همین بازگشت از سمت خروجی به سمت ورودی است.
کاهش گرادیان (gradient descent) در شبکه های عصبی در واقع پایه ی عملیات پس انتشار خطا می باشد.
ما با کم و زیاد کردنِ مقدارِ وزن می خواهیم کمترین میزانِ خطا را مشخص کنیم.
در روشِ کاهش گرادیان برای پیدا کردن وزن از قوانین مشتق استفاده می شود. مشتق، نشان دهنده ی شیبِ خطِ مماس بر یک نقطه از یک تابع است.

 اگر مشتق که همان شیب خطِ مماس بر یک نقطه است یک عدد منفی باشد(یعنی خط به سمت پایین)، الگوریتمِ پس انتشار می داند که اگر شیبِ خط در یک نقطه (با توجه به وزن ها) منفی بود بایستی مقدار آن وزن راافزایش دهد تا شیب خط به صفر برسد.
 با مثبت بودنِ شیب خط، یعنی همان مشتق در آن نقطه، الگوریتمِ پس انتشار می فهمد که باید وزن را کم کند تا شیب به صفر برسد.
  
 ![22-5.png](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/smahdimoghaddasi/EXC%20(22)/22-5.png)
  
الگوریتمِ پس انتشار می تواند با استفاده از این تکنیک یک نقطه ی کمینه برای خطا پیدا کند که البته کمترین مقدار در کل فضا نیست ولی به هر حال معقول به نظر می رسد. به این نقطه ی معقول یک کمینه ی محلی (local minimum) برای خطا می گویند. 
البته رسیدن به نقطه ی سراسری برای الگوریتمِ پس انتشارِ خطا کار دشوار و زمان بری است.

برای همین معمولاً الگوریتم در شبکه های عصبی این گونه آموزش می بیند که به تعداد تکرار مشخص یا تا رسیدن به یک خطای کمِ مشخص الگوریتم را ادامه بدهد و بعد از آن توقف کند. یعنی شبکه عصبی آنقدر تکرار را انجام می دهد تا به یک خطای معقول مشخصِ کم برسد .
 اگر این طور نشد یعنی خطا به اندازه ی دلخواه ما کم نشد، حالا می توانیم برای تکرار محدودیت بگذاریم. مثلاً می گوییم تا ۱۰ هزار مرتبه تکرار را انجام بده (یعنی ۱۰ هزار مرتبه وزن ها و انحراف را آپدیت کن) و بعد از آن دیگر یادگیری را ادامه نده.
حال که یادگیری انجام شد، شبکه دارای وزن ها و انحرافِ مشخص است. از این به بعد شبکه می تواند یک سری ویژگی را بگیرد و کلاس و لیبل راتشخیص دهد، که البته همان طور که واضح است،این پیش بینی دارای خطایی نیز هست.
<br/> 
  
 مشکلات روش کاهش گرادیان:
 <br/>
ممكن است همگراشدن به يك مقدارمينيمم زمان زيادي لازم داشته باشد.
 <br/> 
اگر در سطح خطا چندين مينيمم محلي وجودداشته باشد تضميني وجود ندارد كه الگوريتم 
مينيمم مطلق راپيدا بكند.
  
در ضمن این روش وقتی قابل استفاده است که:
<br/>
فضاي فرضيه داراي فرضيه هاي پارامتريك پيوسته باشد.
<br/>
رابطه خطاقابل مشتق گيري باشد.
  
  <br/>
  ### Eager and lazy learning:
       
      
  
      
      
  

