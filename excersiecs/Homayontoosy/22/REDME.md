<div dir="rtl">
سوال: مفاهیم زیر را به صورت خلاصه بررسی کنید.
<br/>  
Ovefitting
<br/>
Local minimum
<br/>
Gradient descent
<br/>
Eager and lazy learning
</div>
<br/>

<div dir="rtl">
Ovefitting
فرض کنید شما برای امتحان آخرِ ترم در حال درس خواندن هستید. استاد هم به شما ۱۰۰ عدد نمونه سوال داده است تا با استفاده از آن‌ها بتوانید خود را برای امتحان آماده کنید. اگر طوری مطالعه کنید که فقط این ۱۰۰ نمونه سوال را کامل بلد باشید و هر سوالِ دیگری که کمی از این ۱۰۰ سوال فاصله داشته باشد، اشتباه جواب دهید، یعنی ذهنِ شما بر روی سوالات آموزشی که استاد برای یادگیری داده است Overfit  یا بیش‌برازش شده است.  
</div>
<div dir="rtl">
 در دنیای الگوریتم‌ها Overfit شدن به معنای این است که الگوریتم فقط داده‌هایی که در مجموعه آموزشی (train set) یاد گرفته است را می‌تواند به درستی پیش‌بینی کند ولی اگر داده‌ای کمی از مجموعه‌ی آموزشی فاصله داشته باشد، الگوریتمی که Overfit شده باشد، نمی‌تواند به درستی پاسخی برای این داده‌های جدید پیدا کند و آن‌ها را با اشتباه زیادی طبقه‌بندی می کند.
</div>

![overfit](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/Homayontoosy/22/2.jpg)
</br>

<div dir="rtl">
 Local minimum
 فرض کنید در یک پاساژ مشغول خرید یک نوعِ خاص کفش هستید و در فروشگاه‌های مختلف، به دنبال فروشگاهی می‌گردید که ارزان‌ترین قیمت را برای آن کفش داشته بدهد. یکی یکی فروشگاه‌ها را سرکشی می‌کنید تا متوجه می‌شوید، مغازه‌های طبقه‌ی ۴ معمولاً اجناس را ارزان‌تر می‌فروشند. پس فروشگاه‌های طبقه‌ی ۴ را با دقتِ بیشتری می‌گردید تا بالاخره به فروشگاهی می‌رسید که ارزان‌ترین قیمت را در طبقه‌ی ۴ در آن پاساژ می‌دهد. در واقع شما به یک حالتِ بهینه دست پیدا کردید ولی این بهینگی مخصوصِ آن پاساژ بوده است. شاید اگر پاساژهای دیگر را می‌گشتید، قیمتی پایین‌تر و بهینه‌تر نیز پیدا می‌کردید. می‌توان گفت شما در یک بهینه‌ی محلی افتاده‌اید و ممکن است در پاساژهای دیگر، قیمت ‌های بهینه‌ تری نیز موجود باشد.
<br/>
<br/>
در دنیای الگوریتم‌ها نیز، وضع به همین صورت است. فرض کنید یک نرم‌افزاری مانند اینستاگرام می‌خواهد به شما یک دوست جدید برای دنبال کردن پیشنهاد دهد. اینستاگرام به دنبالِ این است که بهترین شخصِ مناسب شما را بهتان پیشنهاد دهد. در واقع به دنبال بهینه‌ی سراسری (بهترین شخص در کل اینستاگرام برای معرفی به شما) است. اما پیدا کردن بهترین شخص، نیاز به جستجوی تمامیِ اشخاص در اینستاگرام دارد که طبیعتا این کار در زمان معقولی میسر نیست. پس به جای آن اینستاگرام سعی می‌کند تا جایی که می‌تواند و در یک زمان معقول به دنبال شخصی که مناسب شما باشد بگردد و این کار باعث می‌شود بتواند یک جواب بهینه‌ی محلی را پیدا کرده و به عنوان یک پیشنهاد معقول به شما نمایش دهد.
</div>
 
<br/>
<div dir="rtl">
Gradient descent
بیایید با یک مثال توضیح دهیم. در مثال زیر به دنبال کمترین مقدارِ خطا می‌گردیم. با توجه به وزن‌ها کمترین میزان خطا در وزن ۱.۵ رخ داده است که مقدارِ آن برابر ۱ است. یعنی ما با کم و زیاد کردنِ مقدارِ وزن می‌خواهیم کمترین میزانِ خطا را مشخص کنیم. اما در شبکه‌های عصبی تعداد بسیار بیشتری وزن خواهیم داشت که بایستی به روز شوند. مثلاً در یک شبکه‌ی عصبی برای پردازش تصویر ممکن است تا ۱۰۰۰ یا بیشتر وزن داشته باشیم که در این صورت باید تابعِ خطا را با توجه به هر ۱۰۰۰ وزن مختلف ارزیابی کرده و سپس هر کدام از این وزن‌ها را تغییر داده و دوباره تست کنیم تا میزان خطا به دست آید. همان‌طور که تصور می بینید این عملیات بسیار وقت‌گیر و پرهزینه است. برای غلبه بر این مشکل از روشی به اسم کاهش گرادیان استفاده می‌شود.
فرض کنید به جای مثال بالا، نمودار مقادیر خطا برای وزن، به صورت زیر باشد: 
</div>

![3](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/Homayontoosy/22/3.jpg)
<br/>
<div dir="rtl">
 کمترین میزان خطا در وزن ۷ اتفاق افتاده است. در روش کاهش گرادیان برای پیدا کردن این وزن از قوانین مشتق استفاده می‌شود. برای اینکه کمترین میزانِ خطا را به دست آوریم فرض می‌کنیم یک نقطه‌ی دلخواه (یک وزن دلخواه) را در این تابع در نظر گرفته‌ایم. مثلاً نقطه‌ی ۱ (یعنی وزن ۱). حال به تصویر زیر نگاه کنید:
</div>

![4](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/Homayontoosy/22/4.jpg)
<br/>
<div dir="rtl">
در این نقطه مشتق که همان شیب خطِ مماس بر یک نقطه است یک عدد منفی بوده، چون خط به سمت پایین است. شیب صفر یعنی کمترین میزان خطای ممکن در آن محدوده (برای درکِ بهتر، در همان تصویر بالا، شیب در محدوده‌ی وزنِ ۱.۷۵ را نگاه کنید، یعنی جایی که خطِ سبز در کمترین میزانِخود قرار دارد). همان‌طور که در شکلِ بالا مشخص است، کمترین میزانِ خطای ممکن در آن محدوده برای وزن ۱.۷۵ ثبت شده است که شیبِ خط در آن‌جا صفر است (موازی محور افقی است)، حال اگر کمی مقدار وزن را از ۱.۷۵ بیشتر کنیم شیب خط مثبت می‌شود، یعنی شیب به سمت بالا می‌رود. با مثبت بودنِ شیب خط، یعنی همان مشتق در آن نقطه، الگوریتم پس انتشار می فهمد که باید وزن را کم کند تا شیب به صفر برسد. 
همان طور که در مثال بالا دیدید، الگوریتم پس انتشار می‌تواند با استفاده از این این تکنیک یک نقطه‌ی کمینه برای خطا پیدا کند که البته کمترین مقدار در کل فضا نبود ولی به هر حال معقول به نظر می‌رسید. به این نقطه‌ی معقول یک کمینه‌ی محلی برای خطا می گویند. در شکل بالا وزن 7 یک کمینه سراسری، یعنی بهترین نقطه موجود در کل شکل است. البته رسیدن به این نقطه‌ی سراسری برای الگوریتمِ پس انتشارِ خطا کار دشوار و زمان‌بری است.
برای همین معمولاً الگوریتم در شبکه‌های عصبی اینگونه آموزش می‌بیند که به تعداد تکرار مشخص یا تا رسیدن به یک خطای کمِ مشخص الگوریتم را ادامه بدهد و بعد از آن توقف کند. یعنی شبکه عصبی آنقدر تکرار را انجام می‌دهد تا به یک خطای معقول مشخصِ کم برسد . مثلاً در مثال بالا می‌گوییم اگر خطا زیر ۲/۵ شد دیگر کافی است. اگر این طور نشد یعنی خطا به اندازه‌ی دلخواه ما کم نشده است و حالا می‌توانیم برای تکرار محدودیت بگذاریم. مثلا می‌گوییم تا ۱۰ هزار مرتبه تکرار را انجام بده (یعنی ۱۰ هزار مرتبه وزن‌ها و انحراف را آپدیت کن) و بعد از آن دیگر یادگیری را ادامه نده.
حال که یادگیری انجام شد، شبکه دارای وزن‌ها و انحراف مشخص است.
</div>
<br/>

<div dir="rtl">
Eager and lazy learning 
اکثر الگوریتم‌های طبقه‌بندی از روش یادگیری کوشا استفاده می‌کنند. یادگیری کوشا به این صورت عمل می‌کند که با استفاده از داده‌های آموزشی مدل طبقه‌بندی را می‌سازد، سپس این مدل، برای ارزیابی داده‌های آزمایشی مورد استفاده قرار می‌گیرد. اگر نتایج ارزیابی رضایت‌بخش باشد، از مدل بدست‌آمده جهت پیش‌بینی طبقه‌بندی داده‌های ناشناخته ورودی استفاده می‌شود.از این رو یادگیری کوشا پیش از این، بیشتر کار خود را در تدوین مدل انجام داده‌اند.
<div/>
 
<div dir="rtl">
از طرف دیگر یادگیری تنبل هیچ مدلی را قبل از گرفتن داده‌های ناشناخته از ورودی نمی‌سازد و منتظر داده‌های طبقه‌بندی نشده می‌ماند و پس از دریافت شروع به ساخت مدل پیش‌بینی می‌کند.به دلیل اینکه به ازای هر پیش‌بینی داده ورودی باید کل مدل از اول ساخته شود، بنابراین می‌توان گفت یاگیری تنبل زمان زیادی صرف می‌کند. 

•	در متدهای تنبل گاهی تصمیم‌گیری برای چگونگی تعمیم بر روی داده‌های آموزشی به نمونه‌ی آموزشی ارائه شده نیز وابسته می‌شود.

•	متدهای کوشا این وابستگی را نمی‌توانند داشته باشند، زمانی که یک متد کوشا با یک نمونه جدید مواجه می‌شود، تخمین جهانی را انجام داده است.
 
<br/> 

<div dir="rtl">
این دو متد دو تفاوت اساسی دارند:

1.	تفاوت در زمان محاسبات

2.	تفاوت در طبقه‌بندهای تولید شده برای نمونه‌های جدید
نکته کلیدی این است که یادگیری تنبل می‌تواند با ترکیب تخمین‌های موضعی تابع هدف را یاد بگیرد، در حالی که یادگیر کوشا فقط یک تخمین جهانی را با توجه به نمونه آموزشی یاد می‌گیرد. این تفاوت بین یادگیری کوشا و تنبل به تفاوت بین تخمین موضعی و جهانی تابع هدف بر می‌گردد.
به طور خلاصه، متدهای تنبل حق انتخاب بین فرضیه‌ها یا تخمین‌های موضعی تابع هدف برای هر نمونه‌ی جدید را دارند. در حالی که متدهای کوشا محدودترند و باید با استفاده از یک فرضیه کل فضای نمونه را پوشش دهند. البته متدهای کوشا نیز می‌توانند از ترکیبی از تخمین‌های موضعی استفاده کنند. با این وجود،حتی این ترکیب تخمین‌های موضعی قابلیت کامل متدهای تنبل در تغییر بر اساس نمونه‌ی آموزشی مجهول را به یادگیر کوشا نمی‌دهد.
<div/>
