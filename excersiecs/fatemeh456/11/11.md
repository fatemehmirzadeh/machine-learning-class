<div dir="rtl">
فرض كنيد در همان مثال بازي تنيس جدول زير داريم :
<br/>
  </div>
| Example | Size  | Color | Shape    | Class |
|---------|-------|-------|----------|-------|
| 1       | big   | red   | circle   | no    |
| 2       | big   | red   | triangle | yes   |
| 3       | small | red   | circle   | no    |
| 4       | big   | red   | triangle | no    |
| 5       | small | blue  | circle   | no    |
<br/>
<div dir="rtl">
این روش ، بهبود یافته درخت تصمیم است که جزء الگوریتم های clssification است.
<br/>
 در این روش با مفهومی به نام آنپروپی رو به ور هستیم که میزان بی نظمی سیستم را نشان میدهد. عددی بین صفر و یک که هر چه کمتر باشد سیستم قطعی تر است.
  <br/>
  
 آنتروپی  را به صورت زیر محاسبه می کنیم :
<br/>
'''Entropy(s) = - (p+ log p+  +  p- log p-)'''
<br/>
  می دانیم احتمال نیز عددی بین صفر و یک است پس خواهیم دید که آنتروپی همیشه عددی مثبت به دست خواهد آمد.
  <br/>
  برای مثال ما آنتروپی به شکل زیر خواهد بود :
  <br/>
'''Entropy(s) = -(3/5 log 3/5 + 2/5 log 2/5) = 0.97'''
<br/>
   ما از این روش برای یافتن موثرترین ویژگی جهت قرار دادن در درخت تصمیم استفاده می کنیم. که برای این کار در درخت تصمیم قبلی معیار ویژگی با کمترین خطا بود ولی در اینجا ملاک ما مفهومی به نام Information Gain است.
  <br/>
حالا به ازای ویژگی های مختلف باید Gain را محاسبه کرده و ویژگی با بیشترین Gain را در ریشه قرار می دهیم .
<br/>
  فرمول آن بدین شکل است :
  <br/>
  
'''Gain (S,A) = Entropy(s) - ∑|s_v |/|s|  E(S_v )'''
  <br/>
  در ادامه این مفهوم را برای تمام ویژگی ها محاسبه می کنیم:
  <br/>
<br/> '''Gain (s , color) = 0.97 - [(3/5 * (-(1/3 log 1/3 + 2/3 log 2/3))) + 0 + 0)] = 0.4192'''
<br/>Gain (s , toughness) = 0.97 - [(4/5 * 1 + 1/5 * 1)] = 0.17'''
<br/>Gain (s , fungus) = 0.97 - [[(3/5 * (-(1/3 log 1/3 + 2/3 log 2/3))) + 0)] = 0.4192'''
  
<br/>
حال ویژگی با بالاترین gain را در ریشه قرار می دهیم.
<br/>
دو ویژگی مقادیر یکسانی دارند پس تفاوتی بین آن ها نیست.
<br/>
ما color را در ریشه قرار داده و مراحل بالا را به ازای بقیه حالات تکرار می کنیم.
<br/>
به ازای رنگ های brown و orange سیستم قطعی است و پاسخ yes می دهد.
<br/>
حال به ازای رنگ green ما مراحل بالا را تکرار می کنیم.
<br/>
'''Entropy(s) = -(1/3 log 1/3 + 2/3 log 2/3) = 0.918
<br/>Gain (s , toughness) = 0.918 - [3/3 * (1/3 log 1/3 + 2/3 log 2/3) + 0] = 0'''
<br/>Gain (s , fungus) = 0.918 - [0] = 0.918'''
<br/>
ویژگی foungus مقدار gain بیشتری دارد آن را در ادامه در ریشه قرار داده و درخت را رسم می کنیم.
</div>
![tree](https://raw.githubusercontent.com/semnan-university-ai/machine-learning-class/main/excersiecs/fatemeh456/11/Tree.PNG?token=AWODYOZLLTHV4F6NFQC7X23BWRS3C)
