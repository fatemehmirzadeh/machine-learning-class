# ویژگی الگوریتم id3

درخت تصمیم id3 از یک مقدار اماری به نام بهره اطلاعات information gain استفاده میکند تا مشخص شود که یک ویزگی تا چه مقدار قادر است مثال های اموزشی را بر حسب دسته بندی آن ها جدا کند.

انتوپی یک تابع را اندازه گیری میزان خلوص (بینظمی یا خالص نبودن) ان میگویند. در هر گره خصوصیتی که بیشترین کاهش را در انتروپی نمونه ها ایجاد کند انتخاب میشود.

Entropy(S)= -((p+ logp+) + (p-logp-))

بهره اطلاعات یک ویژگی عبارت است از مقدار کاهش انتروپی که به واسطه جداسازی مثال ها از طریق این ویژگی حاصل میشود.

IG(S, A) = Entropy(S) - ∑((|Sᵥ| / |S|) * Entropy(Sᵥ))
 
 S تعداد داده ها 
 
 A ویژگی خاص
 
 |S| تعداد کل مثال ها
 
 |Sv| مقادیر خاص ویژگی

در الگوریتم id3 درخت تصمیم از بالا به پایین ساخته میشود. این الگوریتم با این سوال شروع میشود که کدام ویژگی باید در ریشه درخت مورد ازمایش قرار گیرد؟

برای یافتن جواب از یک ازمون اماری استفاده میشود تا مشخص گردد هر کدام تا چه حد قادر است به تنهایی مثال های ازمایشی را دسته بندی کند.

الگوریتم id3 هر شاخه از درخت را آنقدر به عمق میبرد که بتواند به طور کامل مثال های اموزشی را دسته بندی کند. این امر میتواند منجر به overfiting شود.

برای جلوگیری از overfiting باید از رشد درخت قبل از رسیدن به مرحله ای که به طور کامل داده های اموزشی را دسته بندی نماید جلوگیری کرد.  راه دیگر اجازه به رشد درخت و سپس هرس کردن شاخه هایی که مفید نیستن هست.

روش id3 محدود به توابع و ویژگی هایی با مقادیر گسسته است برای استفاده از این روش در مقادیر پیوسته باید به نحوی گسسته سازی صورت گیرد.
