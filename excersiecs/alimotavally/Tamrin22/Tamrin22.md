<div dir="rtl">
  
  ### مفاهیم زیر را به صورت خلاصه بررسی کنید.
  
  <br/>
  
  #### Ovefitting:
  
  <br/>
  <div dir="rtl">
  
  درواقع Over-fitting به این موضوع اشاره دارد که مدل ما بسیار خوب آموزش دیده است اما به خوبی تعمیم نیافته است. اجازه دهید با یک مثال واقعی پیش برویم.فرض کنید شما به یک کشور خارجی رفته اید و قصد دارید با تاکسی به جایی بروید و از بد روزگار راننده آن تاکسی شما را تلکه می کند و پول زیادی از شما می گیرد و در نهایت شما می گویید تمامی رانندگان تاکسی آن کشور دزد هستند. Over-generalization یا Over-fitting دقیقا همین چیزی است که در زندگی انسان ها در حال رخ دادن است و جالب است بدانید که ماشین نیز ممکن است در این دام بیفتد اگر به خوبی مراقب عملکردتان نباشید. بنابراین تعریف Over-fit را اینگونه می گوییم که بسیار خوب آموزش دیده است اما قدرت تعمیم پذیری یا Generalization ندارد.<br/>
  
  ![overfit](https://files.virgool.io/upload/users/5381/posts/fvu1pnuheefs/i93eepbmnxe4.png)
  
   <br/>
  
  #### Local minimum:
  
  <br/>
  <div dir="rtl">
  در علم کامپیوتر، جستجوی محلی یک روش فرا ابتکاری برای حل مسائل بهینه‌سازی سخت، به صورت محاسباتی می‌باشد. جستجوی محلی می‌تواند در مسائلی مورد استفاده قرار گیرد که می‌تواند به عنوان یافتن راه حلی برای حداکثر رساندن یک معیار در میان تعدادی از راه حل‌های پیش رو، مطرح شود. الگوریتم‌های جستجوی محلی از یک راه حل به راه حل دیگر در فضایی از راه حل‌های پیش رو (فضای جستجو) با استفاده از تغییرات محدود حرکت می‌کنند تا یک راه حل به نظر مطلوب یافت شود یا یک زمانی سپری شود. الگوریتم‌های جستجوی محلی در تعداد زیادی از مسائل سخت محاسباتی، از جمله مسائلی از علم کامپیوتر (مخصوصا هوش مصنوعی)، ریاضیات، تحقیق در عملیات، مهندسی، بیو انفورماتیک به‌طور گسترده به کار می‌رود. نمونه‌های از الگوریتم‌های جستجوی محلی، الگوریتم‌های WalkSAT و الگوریتم 2-opt برای مسئله فروشنده دوره گرد می‌باشد.<br/>
  
 ![overfit](https://blog.faradars.org/wp-content/uploads/2018/12/absolute-extrema1.jpg)

   <br/>
  
  #### Gradient descent:
  
  <br/> 
  
گرادیان کاهشی رایج ترین الگوریتم بهینه سازی در یادگیری ماشین و یادگیری عمیق به حساب می آید. این یک الگوریتم بهینه سازی مرتبه اول (first-order) است. این بدان معنی است که هنگام به روزرسانی های پارامترها فقط مشتق اول را در نظر می گیرد. در هر تکرار پارامترها را در جهت عکس گرادیان تابع هدفJ(w)  به روزرسانی می کنیم آن هم با در نظر گرفتن پارامترهایی که گرادیان با تند ترین شیب به بالا سوق می دهد. اندازه گامی که در هر تکرار برای رسیدن به کمینه محلی (local minimum) برمی داریم با توجه به نرخ یادگیری α تعیین می شود. بنابراین مسیر سراشیبی را دنبال می کنیم تا به کمینه محلی (local minimum) برسیم.<br/>
  
   ![overfit](https://danesh-sara.ir/wp-content/uploads/2021/06/link3-7.png)
   
     <br/>
  
  #### Eager and lazy learning:
  
  <br/>
  eager loading : هنگامی که تمامی عملیات مورد نیاز برای یک عمل پیش از انجام آن انجام شود اصطلاحا گوییم از روش eager loading استفاده شده است.<br/>
lazy-loading: در مواقعی که عملیات مورد نیاز برای اجرای یک عمل در هنگام نیاز به آن انجام گردد، اصطلاحا گوییم lazy-loading استفاده شده است.
