<div dir="rtl">
  
### الگوریتم C4.5  را مطالعه کنید و با ذکر یک مثال آنرا توضیح دهید. 

۱. الگوریتم C4.5 می‌تواند مقادیر گسسته یا پیوسته را در ویژگی‌ها درک کند. در درسِ آشنایی با الگوریتم ID3 این نکته را گفتیم که الگوریتمِ ID3 اولیه نمی‌تواند تفاوتِ مقادیرِ عددیِ پیوسته را درک کند. برای مثال نمی‌تواند تفاوت بین معدل‌ها را درک کند. ولی الگوریتمِ C4.5 می‌تواند این کار را انجام دهد و مقادیرِ پیوسته را هم درک کرده و بر اساس آن درخت تصمیم را بسازد. مثلاً همان درخت مثالِ درسِ ID3 را مشاهده کنید:<br/><br/>
   ![fever](https://chistio.ir/wp-content/uploads/2018/01/photo_2018-01-21_23-43-16-1-1024x768-1.jpg)
   
   الگوریتمِ ID3 نمی‌تواند یک همچین درختی را با مقادیر پیوسته بسازد زیرا ساختِ این درخت نیازمندِ این است که الگوریتم بتواند تعدادِ مقالات و معدلِ کل را به صورت پیوسته و عددی همراه با یک حدِ آستانه‌ی مشخص (۲ برای تعداد مقالات و ۱۶ برای معدل) پیدا کند و بر اساس آن شاخه‌های زیر درخت‌های چپ و راست را بسازد. ولی این کار توسطِ الگوریتم C4.5 قابل انجام است. (منظور از مقادیر پیوسته مثلاً اعدادی است که پشت سرِ هم می‌آیند و منظور از مقادیر گسسته مثلاً مرد یا زن بودن است)
   
   ۲. الگوریتمِ C4.5 قادر است تا مقادیری که موجود نیستند را هم تحمل کند. برای مثال تصویر زیر را که مانند جدول درس ID3 بود نگاه کنید:<br/><br/>
   ![fever](https://chistio.ir/wp-content/uploads/2018/01/admin-ajax.jpg)
   
   در تصویر بالا مشاهده می‌کنید که تعدادی از داده‌ها وجود ندارند. به این داده‌ها، مقادیرِ ناموجود (missing values) نیز می‌گویند. مثلاً فرد شماره‌ی ۱، تعدادِ مقالات نامعلومی دارد، یعنی در این مجموعه داده نتوانسته‌ایم تعدادِ مقالاتِ فرد ۱ را به دست بیاوریم. الگوریتم C4.5 می‌تواند این مقادیر را تحمل کند و با وجود مقادیری که ناموجود است، درخت تصمیم خود را بسازد. در حالی که الگوریتمی مانند ID3 و بسیاری دیگر از الگوریتم‌های طبقه‌بندی نمی‌توانند با مقادیر ناموجود، مدلِ خود را بسازند.
   
   ۳. سومین موردی که باعث بهینه شدن الگوریتم C4.5 نسبت به ID3 می‌شود، عملیاتِ هرس کردن (prunning) جهت جلوگیری از overfitting است. الگوریتم‌هایی مانند ID3 به خاطر اینکه سعی دارند تا حد امکان شاخه و برگ داشته باشند (تا به نتیجه مورد نظر برسند) با احتمال بالاتری دارای پیچیدگی در ساخت مدل می‌شوند (بحث bias و variance را مطالعه داشته باشید) و این پیچیدگی در بسیاری از موارد الگوریتم را دچار overfitting و خطای بالا می‌کند. اما با عملیات هرس کردن درخت که در الگوریتم C4.5 انجام می‌شود، می‌توان مدل را به یک نقطه بهینه رساند که زیاد پیچیده نباشد (و البته زیاد هم ساده نباشد) و overfitting یا underfitting رخ ندهد.
   
   ۴. مورد چهارم که می‌تواند الگوریتم C4.5 را از بسیاری دیگر از الگوریتم‌ها متمایز کند بحثِ وزن‌دهی (weighting) به ویژگی‌ها است. اجازه بدهید به مثال اشاره شده در درس الگوریتم ID3 برگردیم. شما می‌خواهید یک طبقه‌بند بسازید تا از روی مدلِ ساخته شده پیش‌بینی کند که آیا یک شخص می‌تواند در مقطع دکتری قبول شود یا خیر؟ مانند تصویر:<br/><br/>
   ![fever](https://chistio.ir/wp-content/uploads/2018/01/photo_2018-01-21_23-33-50-1024x706.jpg)
