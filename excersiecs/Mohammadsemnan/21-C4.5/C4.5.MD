ID3 رایج ترین الگوریتم درخت تصمیم گیری مرسوم است اما دارای مشکلاتی است. ویژگی‌ها باید مقادیر اسمی باشند، مجموعه داده‌ها نباید شامل داده‌های از دست رفته باشند، و در نهایت الگوریتم تمایل دارد تا بیش از حد برازش کند. پیشنهاد دهنده‌ی الگوریتمِ ID3 ، بعد از اینکه به نقاط ضعفِ این الگوریتم پی‌برد، در مدتِ کوتاهی الگوریتمِ بعدی خود یعنی C4.5 را طراحی کرد. اکنون، الگوریتم می تواند مدل های تعمیم یافته تری از جمله داده های پیوسته ایجاد کند و می تواند داده های از دست رفته را مدیریت کند

از نقاطِ ضعف الگوریتم ID3 که در C4.5 رفع شده است می‌توان به موارد زیر اشاره کرد.

۱. الگوریتم C4.5 می‌تواند مقادیر گسسته یا پیوسته را در ویژگی‌ها درک کند.

۲. الگوریتمِ C4.5 قادر است تا مقادیری که موجود نیستند را هم تحمل کند.

۳. سومین موردی که باعث بهینه شدن الگوریتم C4.5 نسبت به ID3 می‌شود، عملیاتِ هرس کردن (prunning) جهت جلوگیری از overfitting است.

۴. مورد چهارم که می‌تواند الگوریتم C4.5 را از بسیاری دیگر از الگوریتم‌ها متمایز کند بحثِ وزن‌دهی (weighting) به ویژگی‌ها است.



نمونه آموزشی

![jadval](https://user-images.githubusercontent.com/94211519/146345194-0e749e94-b067-4939-8195-5667bcba63d1.PNG)

ما کاری را که در مثال ID3 انجام داده ایم انجام خواهیم داد. ابتدا باید آنتروپی کلی را محاسبه کنیم

در الگوریتم ID3، ما سود را برای هر ویژگی محاسبه کرده ایم. در اینجا، ما باید به جای سود، نسبت بهره را محاسبه کنیم.

GainRatio(A) = Gain(A) / SplitInfo(A)

SplitInfo(A) = -∑ |Dj|/|D| x log2|Dj|/|D|

![1](https://user-images.githubusercontent.com/94211519/146346361-f0926a99-96a4-41c9-bd8a-eeb854dab4b3.jpg)
![photo_2021-12-16_12-56-20](https://user-images.githubusercontent.com/94211519/146346370-5f096ecb-79fb-439b-8aea-4620ab502083.jpg)

