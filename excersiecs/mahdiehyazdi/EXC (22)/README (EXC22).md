### مفاهیم زیر را به صورت خلاصه بررسی کنید.

- Ovefitting <br/>
<div dir="rtl" align="justify">
  
```
Ovefitting در عملکرد یادگیری بسیار خوب بوده، اما عملکرد آن بر روی مجموعه داده ای های دیگر (dataset) خوب نیست. 
```
  درواقع Over-fitting به این موضوع اشاره دارد که مدل ما بسیار خوب آموزش دیده است اما به خوبی تعمیم نیافته است. اجازه دهید با یک مثال واقعی پیش برویم.فرض کنید شما به یک کشور خارجی رفته اید و قصد دارید با تاکسی به جایی بروید و از بد روزگار راننده آن تاکسی شما را تلکه می کند و پول زیادی از شما می گیرد و در نهایت شما می گویید تمامی رانندگان تاکسی آن کشور دزد هستند. Over-generalization یا Over-fitting دقیقا همین چیزی است که در زندگی انسان ها در حال رخ دادن است و جالب است بدانید که ماشین نیز ممکن است در این دام بیفتد اگر به خوبی مراقب عملکردتان نباشید. بنابراین تعریف Over-fit را اینگونه می گوییم که بسیار خوب آموزش دیده است اما قدرت تعمیم پذیری یا Generalization ندارد.
  <br/>
  این اتفاق زمانی برایتان ممکن است بیفتد که مجموعه داده ای شما خیلی کوچک یا خیلی بزرگ و پیچیده باشد و همچنین شامل داده های نویزی نیز باشد ( البته کوچک بودن نیز به تنهایی می تواند مشکل ساز باشد حتی بدون داده های نویزی ). به همین خاطر می گوییم ماشین نمی تواند با داده های جدید درست نتیجه گیری کند.
</div>
Over-fitting = Good Learning + Not Generalized

زمانی که مدل را ساده تر می کنیم تا ریسک بیش برازش کمتر شود را Regularization یا تنظیم می گوییم.

- Local minimum

- Gradient descent

<div dir="rtl" align="justify">

```
الگوریتم گرادیان کاهشی، یک الگوریتم بهینه‌سازی تکراری مرتبه-اول هست که مینیموم محلی در یک تابع مشتق‌پذیر را پیدا می‌کند.
```
  
گرادیان کاهشی الگوریتمی است که مینیموم‌های محلی را در یک تابع پیدا می‌کند.

می‌خواهم گرادیان کاهشی را طی یک مثال به شما توضیح بدهم. مثال زیر را درنظر بگیرید؛
</div>

- Eager and lazy learning
