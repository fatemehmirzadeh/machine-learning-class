### تاریخچه پیدایش تئوری بیز را بررسی کنید و مزایا و معایب این تئوری را بررسی کنید.

<div dir="rtl" align="justify">
قضیه بیز (به انگلیسی: Bayes' theorem) روشی برای دسته‌بندی پدیده‌ها، بر پایه احتمال وقوع یا عدم وقوع یک پدیده‌است و در نظریه احتمالات با اهمیت و پرکاربرد است. اگر برای فضای نمونه‌ای مفروضی بتوانیم چنان افرازی انتخاب کنیم که با دانستن اینکه کدامیک از پیشامدهای افراز شده رخ داده‌است، بخش مهمی از عدم قطعیت تقلیل می‌یابد.

این قضیه از آن جهت مفید است که می‌توان از طریق آن، احتمال یک پیشامد را با مشروط کردن نسبت به وقوع یا عدم وقوع یک پیشامد دیگر محاسبه کرد. در بسیاری از حالت‌ها، محاسبهٔ احتمال یک پیشامد به صورت مستقیم کاری دشوار است. با استفاده از این قضیه و مشروط کردن پیشامد مورد نظر نسبت به پیشامد دیگر، می‌توان احتمال مورد نظر را محاسبه کرد.

این رابطه به خاطر بزرگداشت توماس بیز فیلسوف انگلیسی به نام فرمول بیز معروف است.
  در نیمه دوم قرن ۱۸، هنوز شاخه‌ای از ریاضیات به نام آمار و احتمال بوجود نیامده بود. در نتیجه بیشتر قضیه‌ها و تئوری‌‌های احتمال توسط ریاضی‌دانان شناخته و اثبات می‌شد. به این ترتیب اصول و قضیه‌های احتمال را «الگوهای شانس«» (Doctrine of Chances) می‌نامیدند زیرا در کتابی که توسط دمویر (Abraham de Moievre) نوشته شده بود، او از این اصطلاح استفاده کرده بود. در مقاله‌ای با نام «روش‌های محاسبات در الگوهای شانسی» (An Essay towards solving a Problem in the Doctrine of Chances) که توسط بیز در سال 1763 نوشت و توسط دوستش ریچار پرایس (Richard Price) منتشر شد نیز به بررسی شیوه محاسبه احتمال برای پدیده‌های شانسی و تصادفی پرداخته شده است.

او در این مقاله که به نظر ساده می‌آمد، احتمال توام، احتمال شرطی و احتمال حاشیه‌ای را مطرح کرد و به کمک آن‌ها عکس قضیه احتمال شرطی را ارائه داد.

از آن به بعد بین دو گروه از پیروان مکتب «احتمال برمبنای فراوانی» (Probability Bases on Frequency) و  «احتمال برمبنای بیز» (Bayesian Probability) اختلاف نظر و درگیری‌های زیادی بوجود آمده است. ولی بهتر است به دور از این اختلاف نظرها به منطق و دستآورد قضیه بیز بپردازیم.

  در ادامه به  بررسی فرمول تئوری بیز میپردازیم :
  
  P(h│D)= (P(D│h)P(h))/P(D)

در این فرمول :  
P(h│D): احتمال پسین
<br/>
P(D): احتمال داده های آموزش
<br/>
P(h)): احتمال پیشین
<br/>
likelihood:P(D│h)
  میباشد.
  
  
#### مزایای روش بیز 

1- دسته‌بندی کردن داده‌های آزمایشی آسان و سریع است. همچنین زمانی که تعداد دسته‌ها از دو بیشتر باشد نیز عملکرد خوبی از خودش نشان می‌دهد.
2-تا زمانی که شرط مستقل بودن برقرار باشد، یک دسته‌بندی‌کننده بیز ساده عملکرد بهتری نسبت به مدل‌های دیگر مانند رگرسیون لجستیک دارد و به حجم آموزش کمی نیاز دارد.
3-در حالتی که ورودی‌هایمان دسته‌بندی شده باشند این روش عملکرد بهتری نسبت به حالی دارد که ورودی‌هایمان عدد باشند. برای حالتی که ورودی عدد باشد معمولاً فرض می‌شود که از توزیع نرمال پیروی می‌کنند. (که فرض قوی‌ای است

  #### معایب روش بیز 
1- در صورتی که ورودی‌مان دسته‌بندی شده باشد و در مرحلهٔ یادگیری دسته‌ای وجود داشته باشد که دسته‌بندی‌کننده هیچ داده‌ای از آن دسته مشاهده نکرده باشد، دسته‌بندی‌کننده احتمالی برابر صفر برای آن دسته در نظر می‌گیرد و قادر به دسته‌بندی کردن نخواهد بود. برای حل این مشکل می‌توان از تکنیک‌های هموارسازی مانند تخمین‌گر لاپلاس استفاده کرد.

2-یکی دیگر از معایب این دسته‌بندی‌کننده این است که دستیابی به شرط مستقل بودن در دنیای واقعی تقریباً غیرممکن است.

</div>
