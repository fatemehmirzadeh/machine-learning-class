{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5dquBjASQ2C",
        "outputId": "e17f5361-0516-47f7-ec46-04aa7426a7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "wordList = {}\n",
        "spam = pd.read_csv('./gdrive/MyDrive/spam-words.txt', encoding='utf-8')\n",
        "\n",
        "def word_list(text):\n",
        "  indx = len(wordList)\n",
        "\n",
        "  for word in text:\n",
        "    wordList[word] = indx\n",
        "    indx += 1\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  for i in range(spam.shape[0]):\n",
        "    text = spam.iloc[i,0].split()\n",
        "  print('the length of vokabulary is ', len(wordList))\n",
        "\n",
        "  word_list(text)\n",
        "\n",
        "file = open(\"word_list.txt\", \"w\")\n",
        "file.write(str(wordList))\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVEnbjKgSZ-Z",
        "outputId": "c5ad4644-5766-46c0-e201-379dd7bf3733"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the length of vokabulary is  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "data = pd.read_csv('./gdrive/MyDrive/sms_data.txt', encoding='utf-16')\n",
        "file = open('word_list.txt', 'r', encoding='utf-8')\n",
        "cntnt = file.read()\n",
        "word_list = ast.literal_eval(cntnt)\n",
        "\n",
        "x = np.zeros((data.shape[0], len(word_list)))\n",
        "y = np.zeros((data.shape[0]))\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "  sms = data.iloc[i,0].split()\n",
        "\n",
        "for sms_word in sms:\n",
        "  if sms_word.lower() in word_list:\n",
        "    x[i, word_list[sms_word]] +=1\n",
        "    #y[i] = data.iloc[i, 0]\n",
        "\n",
        "np.save('/content/gdrive/MyDrive/dataset/x.npy', x)\n",
        "np.save('/content/gdrive/MyDrive/dataset/y.npy', y)"
      ],
      "metadata": {
        "id": "3OU5Djp9TH5z"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class naivebayes():\n",
        "  def __init__(self, X, y):\n",
        "    self.num_examples, self.num_features = X.shape\n",
        "    self.num_classes = len(np.unique(y))\n",
        "    self.eps = 1e-6\n",
        "  def fit(self, X, y):\n",
        "    self.classes_mean = {}\n",
        "    self.classes_variance = {}\n",
        "    self.classes_prior = {}\n",
        "\n",
        "    for c in range(self.num_classes):\n",
        "      X_c = X[y==c]\n",
        "      self.classes_mean[str(c)] = np.mean(X_c, axis=0)\n",
        "      self.classes_variance[str(c)] = np.var(X_c, axis=0)\n",
        "      self.classes_prior[str(c)] = X_c.shape[0]/self.num_examples\n",
        "\n",
        "  def predict(self, X):\n",
        "    probs = np.zeros((self.num_examples, self.num_classes))\n",
        "\n",
        "    for c in range(self.num_classes):\n",
        "      prior = self.classes_prior[str(c)]\n",
        "      probs_c = self.density_function(X, self.classes_mean[str(c)], self.classes_variance[str(c)])\n",
        "      probs[:, c] = probs_c +np.log(prior)\n",
        "\n",
        "    return np.argmax(probs, 1)\n",
        "\n",
        "  def density_function(self, X, mean, sigma):\n",
        "    const = -self.num_features/2 * np.log(2*np.pi) - 0.5*np.sum(sigma+self.eps)\n",
        "    probs = 0.5*np.sum(np.power(x-mean, 2)/(sigma+self.eps), 1)\n",
        "    return const - probs\n",
        " \n",
        "  if __name__ == '__main__':\n",
        "    X = np.load('/content/gdrive/MyDrive/dataset/x.npy')\n",
        "    y = np.load('/content/gdrive/MyDrive/dataset/y.npy')\n",
        "    print(X.shape)\n",
        "    print(y.shape)\n",
        "\n",
        "    NB = naivebayes(X, y)\n",
        "    NB.fit(X, y)\n",
        "    y_pred = NB.predict(X)\n",
        "\n",
        "print(sum(y_pred == y)/X.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2_ub2aeT4zT",
        "outputId": "7df1809c-2634-48ed-e4cb-9f8b5386b982"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(603, 1)\n",
            "(603,)\n",
            "1.0\n"
          ]
        }
      ]
    }
  ]
}