<div dir="rtl">
سوال: مفاهیم زیر را به صورت خلاصه بررسی کنید.
<br/>  
Ovefitting
<br/>
Local minimum
<br/>
Gradient descent
<br/>
Eager and lazy learning
</div>
<br/>
<div dir="rtl">  
<br/>  
Ovefitting
<br/>
Over-fit عملکرد یادگیری بسیار خوب بوده، اما عملکرد بر روی مجموعه داده ای های دیگر (dataset) خوب نیست.
<div/>
<br/>
<div dir="rtl"> 
 Local minimum
<br/>
این اتفاق زمانی برایتان ممکن است بیفتد که مجموعه داده ای شما خیلی کوچک یا خیلی بزرگ و پیچیده باشد و همچنین شامل داده های نویزی نیز باشد ( البته کوچک بودن نیز به تنهایی می تواند مشکل ساز باشد حتی بدون داده های نویزی (. به همین خاطر می گوییم ماشین نمی تواند با داده های جدید درست نتیجه گیری کند.
<div/>
<br/>
<div dir="rtl">  
Gradient descent
<br/>
گرادیان کاهشی» (Gradient Descent) یک الگوریتم بهینه‌سازی برای پیدا کردن کمینه یک تابع است. در این الگوریتم کار با یک نقطه تصادفی روی تابع آغاز می‌شود و روی جهت منفی از گرادیان تابع حرکت می‌کند تا به کمینه محلی/سراسری برسد.

 در روش  گرادیان کاهشی در  صورتی که مقداردهی اولیه به گونه ای باشد که نقطه اولیه در سمت چپ منحنی قرار گیرد، الگوریتم به یک مینیمم محلی ختم خواهد شد. اما اگر مقداردهی اولیه به گونه ای صورت گیرد که نقطه اولیه در سمت راست منحنی قرار گیرد، الگوریتم به نقطه هدف، یعنی مینیمم سراسری ختم خواهد شد. بنابراین مقداردهی اولیه در الگوریتم Gradient Descent بسیار حائز اهمیت است.
<div/>
<br/>
<div dir="rtl">  
Eager and lazy learning
<br/>
 Eagerوقتی مثال ها را می بیند سعی می کند روی ان انالیز و تحلیل بکند و بر اساس انها یک فرضیه بسازد و پس از اینکه فرضیه را ساخت دیگر با مثال های اموزشی کاری ندارد و بر اساس فرضیه به سوالات پاسخ میدهد   و یک فرضیه عمومی میسازد مانند درخت تصمیم.

<br/>
Lazy: زمانیکه مثال های ازمایشی را دریافت میکند عملی انجام نمیدهد تا زمانی که سوال از ان پرسیده شود میرود سراغ مثال ها و سوال به هر کدام از مثال ها شباهت بیشتری داشت ان را به عنوان جواب انتخاب می کند و یک فرضیه محلی میسازد .مانند KNN
<div/>
<br/>