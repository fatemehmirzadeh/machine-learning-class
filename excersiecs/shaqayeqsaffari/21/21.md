<div dir="rtl">
#21. 
<br/> 
<br/> 
این الگوریتم یکی از تعمیم های الگوریتم ID3 است که از معیار نسبت بهره( gain ratio) استفاده می­ کند. الگوریتم هنگامی متوقف می‌شود که تعداد نمونه ها کمتر از مقدار مشخص شده‌ای باشد. این الگوریتم از تکنیک پس هرس استفاده می‌کند و همانند الگوریتم قبلی داده‌های عددی را نیز می­پذیرد.
<br/>
 نحوه ساخت درخت با  gain ratio بصورت زیر همان طور که روی کاغذ با فرمول ها نوشتم، است.
</div>
<br/>
![GR](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/shaqayeqsaffari/21/GR.jpg)

 
<br/>
<div dir="rtl">
 نقاطِ ضعف الگوریتم ID3  که در C4.5  رفع شده است می‌توان به موارد زیر اشاره کرد:
<br/>
الگوریتم C4.5    می‌تواند مقادیر گسسته یا پیوسته را در ویژگی‌ها درک کند
<br/>
برای مثال  الگوریتمِ ID3 اولیه نمی‌تواند تفاوت بین معدل‌ها را درک کند. ولی الگوریتمِ C4.5 می‌تواند این کار را انجام دهد و مقادیرِ پیوسته را هم درک کرده و بر اساس آن درخت تصمیم را بسازد مثلا در درخت زیر الگوریتم id۳ نمیتواند همچین درختی را با مقادیر پیوسته بسازد زیرا ساخت این درخت نبازمند این است که الگوریتم بتواند تعدادِ مقالات و معدلِ کل را به صورت پیوسته و عددی همراه با یک حدِ آستانه‌ی مشخص (۲ برای تعداد مقالات و ۱۶ برای معدل) پیدا کند و بر اساس آن شاخه‌های زیر درخت‌های چپ و راست را بسازد. ولی این کار توسطِ الگوریتم C4.5 قابل انجام است. (منظور از مقادیر پیوسته مثلاً اعدادی است که پشت سرِ هم می‌آیند و منظور از مقادیر گسسته مثلاً مرد یا زن بودن است) . 
<br/>
 </div>
<br/>
![photo](https://github.com/semnan-university-ai/machine-learning-class/blob/7d2a118dd45119b3f83bac09052be64ddc9d299e/excersiecs/shaqayeqsaffari/21/photo_2018-01-21_23-43-16-1-1024x768-1.jpeg)
<br/>
<div dir="rtl">
<br/>
الگوریتم C4.5   قادر است با وجود مقادیر گمشده نیز درخت تصمیم(decision tree) خود را بسازد، در حالی که الگوریتمی مانند ID3 و بسیاری دیگر از الگوریتم‌های طبقه‌بندی نمی‌توانند با وجود مقادیر گمشده، مدلِ خود را بسازند.
<br/>
در تصویر شامل جدول مشاهده میشود که تعدادی از داده‌ها وجود ندارند. به این داده‌ها، مقادیرِ ناموجود (missing values) نیز می‌گویند. مثلاً فرد شماره‌ی ۱، تعدادِ مقالات نامعلومی دارد، یعنی در این مجموعه داده نتوانسته‌ایم تعدادِ مقالاتِ فرد ۱ را به دست بیاوریم. الگوریتم C4.5 می‌تواند این مقادیر را تحمل کند و با وجود مقادیری که ناموجود است، درخت تصمیم خود را بسازد. در حالی که الگوریتمی مانند ID3 و بسیاری دیگر از الگوریتم‌های طبقه‌بندی نمی‌توانند با مقادیر ناموجود، مدلِ خود را بسازند.
 <br/>
 </div>
   <br/>
![photo](https://github.com/semnan-university-ai/machine-learning-class/blob/main/excersiecs/shaqayeqsaffari/21/admin-ajax.jpeg)
<br/>
<div dir="rtl">
سومین موردی که باعث بهینه شدن الگوریتم  C4.5  نسبت به ID3  می‌شود، عملیاتِ هرس کردن جهت جلوگیری از بیش برازش می‌باشد. الگوریتم‌هایی مانند ID3  به خاطر اینکه سعی دارند تا حد امکان شاخه و برگ داشته باشند (تا به نتیجه مورد نظر برسند) با احتمال بالاتری دارای پیچیدگی در ساخت مدل و این پیچیدگی در بسیاری از موارد الگوریتم را دچار بیش برازش و خطای بالا می‌کند.اما باعملیات هرس کردن درخت که در الگوریتم 5  انجام می‌شود، می‌توان مدل را به یک نقطه بهینه رساند که زیاد پیچیده نباشد (و البته زیاد هم ساده نباشد) و  بیش برازش یا کم برازش(Underfitting) رخ ندهد.
د<br/>
الگوریتم C4.5 این قابلیت را دارد که وزن‌های مختلف و غیر یکسانی را به برخی از ویژگی‌ها بدهد.
<br/>
مثلا میخواهیم طبقه بندی را جوری بسازیم تا از روی مدلِ ساخته شده پیش‌بینی کند که آیا یک شخص می‌تواند در مقطع دکتری قبول شود یا خیر؟
<br/>
حال فرض کنید، شما به عنون رئیسِ دانشکده (با توجه به تجربه‌ی بالای خود) می‌خواهید وزنِ ویژگیِ تعداد مقالات را بیشتر کنید. یعنی به این نتیجه رسیده‌اید که این ویژگی می‌تواند اثر بیشتری در انتخاب یک شخص در مقطع دکتری داشته باشد. الگوریتم C4.5 این قابلیت را دارد که وزن‌های مختلف و غیر یکسانی را به برخی از ویژگی‌ها بدهد. 
<br/> 
<br/> 

<br/>

</div>
